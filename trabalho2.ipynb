{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 2 de IA\n",
    "\n",
    "* Bruno Alvarenga Colturato,   11200251\n",
    "* Che Fan Pan,                 11200421\n",
    "* Eduardo Cavalari Valença,    11234381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_names = ['cs', \n",
    "            'breast_cancer', \n",
    "            'diabetes', \n",
    "            'driving_behavior',\n",
    "            'employee',\n",
    "            'go_to_college',\n",
    "            'phishing',\n",
    "            'smoking',\n",
    "            'social_network_ads',\n",
    "            'water_quality']\n",
    "\n",
    "datasets_files = list(map(lambda x : 'datasets/' + x + '.csv', datasets_names))\n",
    "datasets = [None] * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS:GO Round Winner Classification - dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[0] = pandas.read_csv(datasets_files[0])\n",
    "datasets[0] = datasets[0].dropna(axis=0)\n",
    "\n",
    "# Transform categorical data into many binary data \n",
    "datasets[0] = pandas.get_dummies(datasets[0], columns=[\"map\"])\n",
    "\n",
    "# Define target column\n",
    "datasets[0] = datasets[0].rename(columns={'round_winner' : 'target'})\n",
    "\n",
    "datasets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast Cancer - dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[1] = pandas.read_csv(datasets_files[1])\n",
    "datasets[1] = datasets[1].dropna(axis=0)\n",
    "\n",
    "# Drop useless column\n",
    "datasets[1] = datasets[1].drop(columns=['id'])\n",
    "\n",
    "# Define target column\n",
    "datasets[1] = datasets[1].rename(columns={'diagnosis' : 'target'})\n",
    "\n",
    "datasets[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes - dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[2] = pandas.read_csv(datasets_files[2])\n",
    "datasets[2] = datasets[2].dropna(axis=0)\n",
    "\n",
    "# Transform categorical data into many binary data \n",
    "columns2 = datasets[2].columns.values.tolist()\n",
    "columns2.remove('Diabetic')\n",
    "datasets[2] = pandas.get_dummies(datasets[2], columns=columns2)\n",
    "\n",
    "# Define target column\n",
    "datasets[2] = datasets[2].rename(columns={'Diabetic' : 'target'})\n",
    "\n",
    "datasets[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driving behavior - dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[3] = pandas.read_csv(datasets_files[3])\n",
    "datasets[3] = datasets[3].dropna(axis=0)\n",
    "\n",
    "# Drop useless column\n",
    "datasets[3] = datasets[3].drop(columns=['Timestamp'])\n",
    "\n",
    "# Define target column\n",
    "datasets[3] = datasets[3].rename(columns={'Class' : 'target'})\n",
    "\n",
    "datasets[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employee - dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[4] = pandas.read_csv(datasets_files[4])\n",
    "datasets[4] = datasets[4].dropna(axis=0)\n",
    "\n",
    "# Transform categorical data into many binary data \n",
    "datasets[4] = pandas.get_dummies(datasets[4])\n",
    "\n",
    "# Define target column\n",
    "datasets[4] = datasets[4].rename(columns={'LeaveOrNot' : 'target'})\n",
    "\n",
    "datasets[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go to college - dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[5] = pandas.read_csv(datasets_files[5])\n",
    "datasets[5] = datasets[5].dropna(axis=0)\n",
    "\n",
    "# Transform categorical data into many binary data \n",
    "datasets[5] = pandas.get_dummies(datasets[5])\n",
    "\n",
    "# Define target column\n",
    "datasets[5] = datasets[5].rename(columns={'in_college' : 'target'})\n",
    "\n",
    "datasets[5][\"target\"] = datasets[5][\"target\"].astype('uint8')\n",
    "\n",
    "datasets[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phishing - dataset[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[6] = pandas.read_csv(datasets_files[6])\n",
    "datasets[6] = datasets[6].dropna(axis=0)\n",
    "\n",
    "# Transform categorical data into many binary data \n",
    "datasets[6] = pandas.get_dummies(datasets[6])\n",
    "\n",
    "# Drop useless column\n",
    "datasets[6] = datasets[6].drop(columns=['Index'])\n",
    "\n",
    "# Define target column\n",
    "datasets[6] = datasets[6].rename(columns={'class' : 'target'})\n",
    "datasets[6][\"target\"].replace(to_replace = -1, value = 0, inplace=True)\n",
    "\n",
    "datasets[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoking - dataset[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[7] = pandas.read_csv(datasets_files[7])\n",
    "datasets[7] = datasets[7].dropna(axis=0)\n",
    "\n",
    "# Transform categorical data into many binary data \n",
    "datasets[7] = pandas.get_dummies(datasets[7])\n",
    "\n",
    "# Drop useless column\n",
    "datasets[7] = datasets[7].drop(columns=['ID'])\n",
    "\n",
    "# Define target column\n",
    "datasets[7] = datasets[7].rename(columns={'smoking' : 'target'})\n",
    "\n",
    "datasets[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social network ads - dataset[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data and drop empty rows\n",
    "datasets[8] = pandas.read_csv(datasets_files[8])\n",
    "datasets[8] = datasets[8].dropna(axis=0)\n",
    "\n",
    "# Transform categorical data into many binary data \n",
    "datasets[8] = pandas.get_dummies(datasets[8])\n",
    "\n",
    "# Drop useless column\n",
    "datasets[8] = datasets[8].drop(columns=['User ID'])\n",
    "\n",
    "# Define target column\n",
    "datasets[8] = datasets[8].rename(columns={'Purchased' : 'target'})\n",
    "\n",
    "datasets[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water quality - dataset[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[9] = pandas.read_csv(datasets_files[9])\n",
    "datasets[9] = datasets[9].dropna(axis=0)\n",
    "\n",
    "# Define target column\n",
    "datasets[9] = datasets[9].rename(columns={'is_safe' : 'target'})\n",
    "\n",
    "datasets[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns except target\n",
    "X = [None] * 10\n",
    "# Target column\n",
    "Y = [None] * 10\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    X[i] = dataset.loc[:, dataset.columns != 'target'] \n",
    "    Y[i] = np.array(dataset.loc[:, dataset.columns == 'target']).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Type of evaluation\n",
    "scoring_choosed = [None] * 10\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    # Para plotar a proporção das classes, primeiro contamos os valores da coluna 'target' e transformamos em um frame\n",
    "    class_distribuition = pandas.DataFrame(dataset['target'].value_counts())\n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "    # Usamos o frame criado acima para plot a frequencia de cada classe no dataset\n",
    "    plot = seaborn.barplot(x=class_distribuition.index, y='target', data = class_distribuition)\n",
    "    plot.set_title(datasets_names[i])\n",
    "\n",
    "    total_sum = sum(class_distribuition['target'])\n",
    "    partition = total_sum/len(class_distribuition['target'])\n",
    "    for value in class_distribuition['target']:\n",
    "        if(0.9*partition <= value <= 1.1*partition):\n",
    "            scoring_choosed[i] = \"accuracy\" \n",
    "        else:\n",
    "            scoring_choosed[i] = \"balanced_accuracy\"\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa metodos de classicacao\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instancia os classificador \n",
    "DTC = DecisionTreeClassifier()\n",
    "KNN = KNeighborsClassifier()\n",
    "GNB = GaussianNB()\n",
    "MLP = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC_parameters = {'criterion' : ['gini','entropy','log_loss'], 'random_state' : [42]}\n",
    "KNN_parameters = {'n_neighbors' : [1, 3, 5, 7, 9, 11, 13], 'weights' : ['uniform', 'distance']}\n",
    "GNB_parameters = {}\n",
    "MLP_parameters = {'hidden_layer_sizes' : [(5), (8), (15), (5, 3), (8, 5), (10, 5)], 'max_iter' : [3000], 'random_state' : [42]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_DTC = [None] * 10\n",
    "GS_KNN = [None] * 10\n",
    "GS_GNB = [None] * 10\n",
    "GS_MLP = [None] * 10\n",
    "\n",
    "for i, choosed in enumerate(scoring_choosed):\n",
    "    GS_DTC[i] = GridSearchCV(DTC, DTC_parameters, cv = 10, scoring = choosed)\n",
    "    GS_KNN[i] = GridSearchCV(KNN, KNN_parameters, cv = 10, scoring = choosed)\n",
    "    GS_GNB[i] = GridSearchCV(GNB, GNB_parameters, cv = 10, scoring = choosed)\n",
    "    GS_MLP[i] = GridSearchCV(MLP, MLP_parameters, cv = 10, scoring = choosed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treina o classificador com o conjunto de treino\n",
    "for i in range(len(datasets)):\n",
    "    GS_DTC[i].fit(X[i], Y[i])\n",
    "    GS_KNN[i].fit(X[i], Y[i])\n",
    "    GS_GNB[i].fit(X[i], Y[i])\n",
    "    GS_MLP[i].fit(X[i], Y[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DTC = [None] * 10\n",
    "results_KNN = [None] * 10\n",
    "results_GNB = [None] * 10\n",
    "results_MLP = [None] * 10\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    results_DTC[i] = pandas.DataFrame(GS_DTC[i].cv_results_)\n",
    "    results_KNN[i] = pandas.DataFrame(GS_KNN[i].cv_results_)\n",
    "    results_GNB[i] = pandas.DataFrame(GS_GNB[i].cv_results_)\n",
    "    results_MLP[i] = pandas.DataFrame(GS_MLP[i].cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = ['params', 'mean_test_score','std_test_score', 'rank_test_score']\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    results_DTC[i] = results_DTC[i][view].sort_values(by='rank_test_score')\n",
    "    results_KNN[i] = results_KNN[i][view].sort_values(by='rank_test_score')\n",
    "    results_GNB[i] = results_GNB[i][view].sort_values(by='rank_test_score')\n",
    "    results_MLP[i] = results_MLP[i][view].sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dataset in enumerate(datasets_names):\n",
    "    print(f'Para o dataset {dataset}:')\n",
    "    print(f'\\tA acurácia do Classificador DTC é: {results_DTC[i][\"mean_test_score\"][0] :.2%}')\n",
    "    print(f'\\tA acurácia do Classificador KNN é: {results_KNN[i][\"mean_test_score\"][0] :.2%}')\n",
    "    print(f'\\tA acurácia do Classificador GNB é: {results_GNB[i][\"mean_test_score\"][0] :.2%}')\n",
    "    print(f'\\tA acurácia do Classificador MLP é: {results_MLP[i][\"mean_test_score\"][0] :.2%}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets_algs = [[] for _ in range(len(datasets))]\n",
    "\n",
    "for i, algs in enumerate(datasets_algs):\n",
    "    algs.append({\"name\": \"DTC\", \"results\": results_DTC[i]})\n",
    "    algs.append({\"name\": \"KNN\", \"results\": results_KNN[i]})\n",
    "    algs.append({\"name\": \"GNB\", \"results\": results_GNB[i]})\n",
    "    algs.append({\"name\": \"MLP\", \"results\": results_MLP[i]})\n",
    "    algs.sort(key = lambda acc : acc[\"results\"][\"mean_test_score\"][0], reverse = True)\n",
    "\n",
    "    print(f'Dataset: {datasets_names[i]}')\n",
    "    for alg in algs:\n",
    "        print(f'\\t{alg[\"name\"]}, media: {alg[\"results\"][\"mean_test_score\"][0]}, dp: {alg[\"results\"][\"std_test_score\"][0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "diferenca_absoluta = [None] * 10\n",
    "\n",
    "for i, algs in enumerate(datasets_algs):\n",
    "    media_err_A0 = 1 - algs[0][\"results\"][\"mean_test_score\"][0]\n",
    "    dp_A0 = algs[0][\"results\"][\"std_test_score\"][0]\n",
    "\n",
    "    media_err_A1 = 1 - algs[1][\"results\"][\"mean_test_score\"][0]\n",
    "    dp_A1 = algs[1][\"results\"][\"std_test_score\"][0]\n",
    "\n",
    "    dif_media_err = media_err_A0 - media_err_A1\n",
    "    desvio_padrao = sqrt( (dp_A0**2 + dp_A1**2) / 2.0 )\n",
    "    diferenca_absoluta[i] = dif_media_err / desvio_padrao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, algs in enumerate(datasets_algs):\n",
    "    print(f'Dataset: {datasets_names[i]}, diferenca_absoluta: {diferenca_absoluta[i]}')\n",
    "    if diferenca_absoluta[i] > 0:\n",
    "        if diferenca_absoluta[i] >= 0.02:\n",
    "            print(f'{algs[1][\"name\"]} tem melhor performance que {algs[0][\"name\"]} com nível de confiança de 95%')\n",
    "        else:\n",
    "            print(f'{algs[1][\"name\"]} tem melhor performance que {algs[0][\"name\"]}')\n",
    "    else:\n",
    "        if diferenca_absoluta[i] <= 0.02:\n",
    "            print(f'{algs[0][\"name\"]} tem melhor performance que {algs[1][\"name\"]} com nível de confiança de 95%')\n",
    "        else:\n",
    "            print(f'{algs[0][\"name\"]} tem melhor performance que {algs[1][\"name\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
