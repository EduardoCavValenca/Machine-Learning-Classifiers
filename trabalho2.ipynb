{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 2 de IA\n",
    "\n",
    "* Bruno Alvarenga Colturato,   11200251\n",
    "* Che Fan Pan,                 11200421\n",
    "* Eduardo Cavalari Valença,    11234381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_names = ['cs', \n",
    "            'breast_cancer', \n",
    "            'diabetes', \n",
    "            'driving_behavior',\n",
    "            'employee',\n",
    "            'go_to_college',\n",
    "            'phishing',\n",
    "            'smoking',\n",
    "            'social_network_ads',\n",
    "            'water_quality']\n",
    "\n",
    "datasets_files = list(map(lambda x : 'datasets/' + x + '.csv', datasets_names))\n",
    "datasets = [None] * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS:GO Round Winner Classification - dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_left</th>\n",
       "      <th>ct_score</th>\n",
       "      <th>t_score</th>\n",
       "      <th>bomb_planted</th>\n",
       "      <th>ct_health</th>\n",
       "      <th>t_health</th>\n",
       "      <th>ct_armor</th>\n",
       "      <th>t_armor</th>\n",
       "      <th>ct_money</th>\n",
       "      <th>t_money</th>\n",
       "      <th>...</th>\n",
       "      <th>t_grenade_decoygrenade</th>\n",
       "      <th>target</th>\n",
       "      <th>map_de_cache</th>\n",
       "      <th>map_de_dust2</th>\n",
       "      <th>map_de_inferno</th>\n",
       "      <th>map_de_mirage</th>\n",
       "      <th>map_de_nuke</th>\n",
       "      <th>map_de_overpass</th>\n",
       "      <th>map_de_train</th>\n",
       "      <th>map_de_vertigo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>391.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>391.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18350.0</td>\n",
       "      <td>10750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122405</th>\n",
       "      <td>15.41</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>True</td>\n",
       "      <td>200.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122406</th>\n",
       "      <td>174.93</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>11500.0</td>\n",
       "      <td>23900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122407</th>\n",
       "      <td>114.93</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122408</th>\n",
       "      <td>94.93</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122409</th>\n",
       "      <td>74.93</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>375.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>T</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122410 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        time_left  ct_score  t_score  bomb_planted  ct_health  t_health  \\\n",
       "0          175.00       0.0      0.0         False      500.0     500.0   \n",
       "1          156.03       0.0      0.0         False      500.0     500.0   \n",
       "2           96.03       0.0      0.0         False      391.0     400.0   \n",
       "3           76.03       0.0      0.0         False      391.0     400.0   \n",
       "4          174.97       1.0      0.0         False      500.0     500.0   \n",
       "...           ...       ...      ...           ...        ...       ...   \n",
       "122405      15.41      11.0     14.0          True      200.0     242.0   \n",
       "122406     174.93      11.0     15.0         False      500.0     500.0   \n",
       "122407     114.93      11.0     15.0         False      500.0     500.0   \n",
       "122408      94.93      11.0     15.0         False      500.0     500.0   \n",
       "122409      74.93      11.0     15.0         False      375.0     479.0   \n",
       "\n",
       "        ct_armor  t_armor  ct_money  t_money  ...  t_grenade_decoygrenade  \\\n",
       "0            0.0      0.0    4000.0   4000.0  ...                     0.0   \n",
       "1          400.0    300.0     600.0    650.0  ...                     0.0   \n",
       "2          294.0    200.0     750.0    500.0  ...                     0.0   \n",
       "3          294.0    200.0     750.0    500.0  ...                     0.0   \n",
       "4          192.0      0.0   18350.0  10750.0  ...                     0.0   \n",
       "...          ...      ...       ...      ...  ...                     ...   \n",
       "122405     195.0    359.0     100.0   5950.0  ...                     0.0   \n",
       "122406      95.0    175.0   11500.0  23900.0  ...                     0.0   \n",
       "122407     495.0    475.0    1200.0   6700.0  ...                     0.0   \n",
       "122408     495.0    475.0    1200.0   6700.0  ...                     0.0   \n",
       "122409     395.0    466.0    1100.0   7000.0  ...                     0.0   \n",
       "\n",
       "        target  map_de_cache  map_de_dust2  map_de_inferno  map_de_mirage  \\\n",
       "0           CT             0             1               0              0   \n",
       "1           CT             0             1               0              0   \n",
       "2           CT             0             1               0              0   \n",
       "3           CT             0             1               0              0   \n",
       "4           CT             0             1               0              0   \n",
       "...        ...           ...           ...             ...            ...   \n",
       "122405       T             0             0               0              0   \n",
       "122406       T             0             0               0              0   \n",
       "122407       T             0             0               0              0   \n",
       "122408       T             0             0               0              0   \n",
       "122409       T             0             0               0              0   \n",
       "\n",
       "        map_de_nuke  map_de_overpass  map_de_train  map_de_vertigo  \n",
       "0                 0                0             0               0  \n",
       "1                 0                0             0               0  \n",
       "2                 0                0             0               0  \n",
       "3                 0                0             0               0  \n",
       "4                 0                0             0               0  \n",
       "...             ...              ...           ...             ...  \n",
       "122405            0                0             1               0  \n",
       "122406            0                0             1               0  \n",
       "122407            0                0             1               0  \n",
       "122408            0                0             1               0  \n",
       "122409            0                0             1               0  \n",
       "\n",
       "[122410 rows x 104 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[0] = pandas.read_csv(datasets_files[0])\n",
    "datasets[0] = datasets[0].dropna(axis=0)\n",
    "\n",
    "# Transform categorical data into many binary data \n",
    "datasets[0] = pandas.get_dummies(datasets[0], columns=[\"map\"])\n",
    "\n",
    "# Define target column\n",
    "datasets[0] = datasets[0].rename(columns={'round_winner' : 'target'})\n",
    "\n",
    "datasets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast Cancer - dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0        M        17.99         10.38          122.80     1001.0   \n",
       "1        M        20.57         17.77          132.90     1326.0   \n",
       "2        M        19.69         21.25          130.00     1203.0   \n",
       "3        M        11.42         20.38           77.58      386.1   \n",
       "4        M        20.29         14.34          135.10     1297.0   \n",
       "..     ...          ...           ...             ...        ...   \n",
       "564      M        21.56         22.39          142.00     1479.0   \n",
       "565      M        20.13         28.25          131.20     1261.0   \n",
       "566      M        16.60         28.08          108.30      858.1   \n",
       "567      M        20.60         29.33          140.10     1265.0   \n",
       "568      B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[1] = pandas.read_csv(datasets_files[1])\n",
    "datasets[1] = datasets[1].dropna(axis=0)\n",
    "\n",
    "# Drop useless column\n",
    "datasets[1] = datasets[1].drop(columns=['id'])\n",
    "\n",
    "# Define target column\n",
    "datasets[1] = datasets[1].rename(columns={'diagnosis' : 'target'})\n",
    "\n",
    "datasets[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diabetes - dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Age_40-49</th>\n",
       "      <th>Age_50-59</th>\n",
       "      <th>Age_60 or older</th>\n",
       "      <th>Age_less than 40</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Family_Diabetes_no</th>\n",
       "      <th>Family_Diabetes_yes</th>\n",
       "      <th>highBP_no</th>\n",
       "      <th>...</th>\n",
       "      <th>BPLevel_normal</th>\n",
       "      <th>Pregancies_0.0</th>\n",
       "      <th>Pregancies_1.0</th>\n",
       "      <th>Pregancies_2.0</th>\n",
       "      <th>Pregancies_3.0</th>\n",
       "      <th>Pregancies_4.0</th>\n",
       "      <th>Pdiabetes_0</th>\n",
       "      <th>Pdiabetes_yes</th>\n",
       "      <th>UriationFreq_not much</th>\n",
       "      <th>UriationFreq_quite often</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>905 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target  Age_40-49  Age_50-59  Age_60 or older  Age_less than 40  \\\n",
       "0       no          0          1                0                 0   \n",
       "1       no          0          1                0                 0   \n",
       "2       no          1          0                0                 0   \n",
       "3       no          0          1                0                 0   \n",
       "4       no          1          0                0                 0   \n",
       "..     ...        ...        ...              ...               ...   \n",
       "946    yes          0          0                0                 1   \n",
       "947    yes          0          0                1                 0   \n",
       "948     no          0          0                1                 0   \n",
       "949     no          0          0                1                 0   \n",
       "950    yes          0          0                1                 0   \n",
       "\n",
       "     Gender_Female  Gender_Male  Family_Diabetes_no  Family_Diabetes_yes  \\\n",
       "0                0            1                   1                    0   \n",
       "1                0            1                   1                    0   \n",
       "2                0            1                   1                    0   \n",
       "3                0            1                   1                    0   \n",
       "4                0            1                   1                    0   \n",
       "..             ...          ...                 ...                  ...   \n",
       "946              0            1                   0                    1   \n",
       "947              0            1                   0                    1   \n",
       "948              0            1                   1                    0   \n",
       "949              0            1                   1                    0   \n",
       "950              1            0                   0                    1   \n",
       "\n",
       "     highBP_no  ...  BPLevel_normal   Pregancies_0.0  Pregancies_1.0  \\\n",
       "0            0  ...                0               1               0   \n",
       "1            0  ...                0               1               0   \n",
       "2            1  ...                0               1               0   \n",
       "3            1  ...                0               1               0   \n",
       "4            1  ...                0               1               0   \n",
       "..         ...  ...              ...             ...             ...   \n",
       "946          1  ...                0               1               0   \n",
       "947          0  ...                0               1               0   \n",
       "948          0  ...                0               1               0   \n",
       "949          0  ...                0               1               0   \n",
       "950          0  ...                0               0               0   \n",
       "\n",
       "     Pregancies_2.0  Pregancies_3.0  Pregancies_4.0  Pdiabetes_0  \\\n",
       "0                 0               0               0            1   \n",
       "1                 0               0               0            1   \n",
       "2                 0               0               0            1   \n",
       "3                 0               0               0            1   \n",
       "4                 0               0               0            1   \n",
       "..              ...             ...             ...          ...   \n",
       "946               0               0               0            1   \n",
       "947               0               0               0            1   \n",
       "948               0               0               0            1   \n",
       "949               0               0               0            1   \n",
       "950               1               0               0            1   \n",
       "\n",
       "     Pdiabetes_yes  UriationFreq_not much  UriationFreq_quite often  \n",
       "0                0                      1                         0  \n",
       "1                0                      1                         0  \n",
       "2                0                      1                         0  \n",
       "3                0                      1                         0  \n",
       "4                0                      1                         0  \n",
       "..             ...                    ...                       ...  \n",
       "946              0                      1                         0  \n",
       "947              0                      0                         1  \n",
       "948              0                      1                         0  \n",
       "949              0                      1                         0  \n",
       "950              0                      0                         1  \n",
       "\n",
       "[905 rows x 91 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[2] = pandas.read_csv(datasets_files[2])\n",
    "datasets[2] = datasets[2].dropna(axis=0)\n",
    "\n",
    "# Transform categorical data into many binary data \n",
    "columns2 = datasets[2].columns.values.tolist()\n",
    "columns2.remove('Diabetic')\n",
    "datasets[2] = pandas.get_dummies(datasets[2], columns=columns2)\n",
    "\n",
    "# Define target column\n",
    "datasets[2] = datasets[2].rename(columns={'Diabetic' : 'target'})\n",
    "\n",
    "datasets[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driving behavior - dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccX</th>\n",
       "      <th>AccY</th>\n",
       "      <th>AccZ</th>\n",
       "      <th>GyroX</th>\n",
       "      <th>GyroY</th>\n",
       "      <th>GyroZ</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059407</td>\n",
       "      <td>-0.174707</td>\n",
       "      <td>0.101938</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.624864</td>\n",
       "      <td>-1.082492</td>\n",
       "      <td>-0.204183</td>\n",
       "      <td>-0.028558</td>\n",
       "      <td>0.051313</td>\n",
       "      <td>0.135536</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.594660</td>\n",
       "      <td>-0.122410</td>\n",
       "      <td>0.220502</td>\n",
       "      <td>-0.019395</td>\n",
       "      <td>-0.029322</td>\n",
       "      <td>0.087888</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.738478</td>\n",
       "      <td>-0.228456</td>\n",
       "      <td>0.667732</td>\n",
       "      <td>0.069791</td>\n",
       "      <td>-0.029932</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.101741</td>\n",
       "      <td>0.777568</td>\n",
       "      <td>-0.066730</td>\n",
       "      <td>0.030696</td>\n",
       "      <td>-0.003665</td>\n",
       "      <td>0.054902</td>\n",
       "      <td>NORMAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3639</th>\n",
       "      <td>0.915688</td>\n",
       "      <td>-2.017489</td>\n",
       "      <td>1.687505</td>\n",
       "      <td>0.450360</td>\n",
       "      <td>0.384845</td>\n",
       "      <td>-1.236468</td>\n",
       "      <td>SLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3640</th>\n",
       "      <td>-1.934203</td>\n",
       "      <td>0.914925</td>\n",
       "      <td>-0.096013</td>\n",
       "      <td>0.321468</td>\n",
       "      <td>0.649350</td>\n",
       "      <td>-0.477162</td>\n",
       "      <td>SLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3641</th>\n",
       "      <td>-0.222845</td>\n",
       "      <td>0.747304</td>\n",
       "      <td>-0.887430</td>\n",
       "      <td>0.361174</td>\n",
       "      <td>-0.406836</td>\n",
       "      <td>0.054291</td>\n",
       "      <td>SLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3642</th>\n",
       "      <td>-0.349423</td>\n",
       "      <td>0.067261</td>\n",
       "      <td>0.394368</td>\n",
       "      <td>-0.132405</td>\n",
       "      <td>0.020159</td>\n",
       "      <td>-0.004963</td>\n",
       "      <td>SLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3643</th>\n",
       "      <td>-0.402428</td>\n",
       "      <td>0.406218</td>\n",
       "      <td>-0.423009</td>\n",
       "      <td>-0.053603</td>\n",
       "      <td>-0.006720</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>SLOW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3644 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          AccX      AccY      AccZ     GyroX     GyroY     GyroZ  target\n",
       "0     0.000000  0.000000  0.000000  0.059407 -0.174707  0.101938  NORMAL\n",
       "1    -1.624864 -1.082492 -0.204183 -0.028558  0.051313  0.135536  NORMAL\n",
       "2    -0.594660 -0.122410  0.220502 -0.019395 -0.029322  0.087888  NORMAL\n",
       "3     0.738478 -0.228456  0.667732  0.069791 -0.029932  0.054902  NORMAL\n",
       "4     0.101741  0.777568 -0.066730  0.030696 -0.003665  0.054902  NORMAL\n",
       "...        ...       ...       ...       ...       ...       ...     ...\n",
       "3639  0.915688 -2.017489  1.687505  0.450360  0.384845 -1.236468    SLOW\n",
       "3640 -1.934203  0.914925 -0.096013  0.321468  0.649350 -0.477162    SLOW\n",
       "3641 -0.222845  0.747304 -0.887430  0.361174 -0.406836  0.054291    SLOW\n",
       "3642 -0.349423  0.067261  0.394368 -0.132405  0.020159 -0.004963    SLOW\n",
       "3643 -0.402428  0.406218 -0.423009 -0.053603 -0.006720  0.001145    SLOW\n",
       "\n",
       "[3644 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[3] = pandas.read_csv(datasets_files[3])\n",
    "datasets[3] = datasets[3].dropna(axis=0)\n",
    "\n",
    "# Drop useless column\n",
    "datasets[3] = datasets[3].drop(columns=['Timestamp'])\n",
    "\n",
    "# Define target column\n",
    "datasets[3] = datasets[3].rename(columns={'Class' : 'target'})\n",
    "\n",
    "datasets[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employee - dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JoiningYear</th>\n",
       "      <th>PaymentTier</th>\n",
       "      <th>Age</th>\n",
       "      <th>ExperienceInCurrentDomain</th>\n",
       "      <th>target</th>\n",
       "      <th>Education_Bachelors</th>\n",
       "      <th>Education_Masters</th>\n",
       "      <th>Education_PHD</th>\n",
       "      <th>City_Bangalore</th>\n",
       "      <th>City_New Delhi</th>\n",
       "      <th>City_Pune</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>EverBenched_No</th>\n",
       "      <th>EverBenched_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4648</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4649</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4653 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      JoiningYear  PaymentTier  Age  ExperienceInCurrentDomain  target  \\\n",
       "0            2017            3   34                          0       0   \n",
       "1            2013            1   28                          3       1   \n",
       "2            2014            3   38                          2       0   \n",
       "3            2016            3   27                          5       1   \n",
       "4            2017            3   24                          2       1   \n",
       "...           ...          ...  ...                        ...     ...   \n",
       "4648         2013            3   26                          4       0   \n",
       "4649         2013            2   37                          2       1   \n",
       "4650         2018            3   27                          5       1   \n",
       "4651         2012            3   30                          2       0   \n",
       "4652         2015            3   33                          4       0   \n",
       "\n",
       "      Education_Bachelors  Education_Masters  Education_PHD  City_Bangalore  \\\n",
       "0                       1                  0              0               1   \n",
       "1                       1                  0              0               0   \n",
       "2                       1                  0              0               0   \n",
       "3                       0                  1              0               1   \n",
       "4                       0                  1              0               0   \n",
       "...                   ...                ...            ...             ...   \n",
       "4648                    1                  0              0               1   \n",
       "4649                    0                  1              0               0   \n",
       "4650                    0                  1              0               0   \n",
       "4651                    1                  0              0               1   \n",
       "4652                    1                  0              0               1   \n",
       "\n",
       "      City_New Delhi  City_Pune  Gender_Female  Gender_Male  EverBenched_No  \\\n",
       "0                  0          0              0            1               1   \n",
       "1                  0          1              1            0               1   \n",
       "2                  1          0              1            0               1   \n",
       "3                  0          0              0            1               1   \n",
       "4                  0          1              0            1               0   \n",
       "...              ...        ...            ...          ...             ...   \n",
       "4648               0          0              1            0               1   \n",
       "4649               0          1              0            1               1   \n",
       "4650               1          0              0            1               1   \n",
       "4651               0          0              0            1               0   \n",
       "4652               0          0              0            1               0   \n",
       "\n",
       "      EverBenched_Yes  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   1  \n",
       "...               ...  \n",
       "4648                0  \n",
       "4649                0  \n",
       "4650                0  \n",
       "4651                1  \n",
       "4652                1  \n",
       "\n",
       "[4653 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[4] = pandas.read_csv(datasets_files[4])\n",
    "datasets[4] = datasets[4].dropna(axis=0)\n",
    "\n",
    "# Transform categorical data into many binary data \n",
    "datasets[4] = pandas.get_dummies(datasets[4])\n",
    "\n",
    "# Define target column\n",
    "datasets[4] = datasets[4].rename(columns={'LeaveOrNot' : 'target'})\n",
    "\n",
    "datasets[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go to college - dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_age</th>\n",
       "      <th>parent_salary</th>\n",
       "      <th>house_area</th>\n",
       "      <th>average_grades</th>\n",
       "      <th>parent_was_in_college</th>\n",
       "      <th>target</th>\n",
       "      <th>type_school_Academic</th>\n",
       "      <th>type_school_Vocational</th>\n",
       "      <th>school_accreditation_A</th>\n",
       "      <th>school_accreditation_B</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>interest_Less Interested</th>\n",
       "      <th>interest_Not Interested</th>\n",
       "      <th>interest_Quiet Interested</th>\n",
       "      <th>interest_Uncertain</th>\n",
       "      <th>interest_Very Interested</th>\n",
       "      <th>residence_Rural</th>\n",
       "      <th>residence_Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>6950000</td>\n",
       "      <td>83.0</td>\n",
       "      <td>84.09</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>4410000</td>\n",
       "      <td>76.8</td>\n",
       "      <td>86.91</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>6500000</td>\n",
       "      <td>80.6</td>\n",
       "      <td>87.43</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49</td>\n",
       "      <td>6600000</td>\n",
       "      <td>78.2</td>\n",
       "      <td>82.12</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>5250000</td>\n",
       "      <td>75.1</td>\n",
       "      <td>86.79</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>49</td>\n",
       "      <td>7420000</td>\n",
       "      <td>63.6</td>\n",
       "      <td>85.99</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>51</td>\n",
       "      <td>7480000</td>\n",
       "      <td>84.3</td>\n",
       "      <td>89.72</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>49</td>\n",
       "      <td>5550000</td>\n",
       "      <td>75.2</td>\n",
       "      <td>79.56</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>53</td>\n",
       "      <td>5840000</td>\n",
       "      <td>105.8</td>\n",
       "      <td>87.18</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>50</td>\n",
       "      <td>2940000</td>\n",
       "      <td>69.1</td>\n",
       "      <td>86.13</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     parent_age  parent_salary  house_area  average_grades  \\\n",
       "0            56        6950000        83.0           84.09   \n",
       "1            57        4410000        76.8           86.91   \n",
       "2            50        6500000        80.6           87.43   \n",
       "3            49        6600000        78.2           82.12   \n",
       "4            57        5250000        75.1           86.79   \n",
       "..          ...            ...         ...             ...   \n",
       "995          49        7420000        63.6           85.99   \n",
       "996          51        7480000        84.3           89.72   \n",
       "997          49        5550000        75.2           79.56   \n",
       "998          53        5840000       105.8           87.18   \n",
       "999          50        2940000        69.1           86.13   \n",
       "\n",
       "     parent_was_in_college  target  type_school_Academic  \\\n",
       "0                    False       1                     1   \n",
       "1                    False       1                     1   \n",
       "2                    False       1                     1   \n",
       "3                     True       1                     0   \n",
       "4                    False       0                     1   \n",
       "..                     ...     ...                   ...   \n",
       "995                   True       1                     0   \n",
       "996                   True       1                     1   \n",
       "997                  False       1                     0   \n",
       "998                   True       1                     1   \n",
       "999                   True       0                     1   \n",
       "\n",
       "     type_school_Vocational  school_accreditation_A  school_accreditation_B  \\\n",
       "0                         0                       1                       0   \n",
       "1                         0                       1                       0   \n",
       "2                         0                       0                       1   \n",
       "3                         1                       0                       1   \n",
       "4                         0                       1                       0   \n",
       "..                      ...                     ...                     ...   \n",
       "995                       1                       1                       0   \n",
       "996                       0                       0                       1   \n",
       "997                       1                       1                       0   \n",
       "998                       0                       0                       1   \n",
       "999                       0                       0                       1   \n",
       "\n",
       "     gender_Female  gender_Male  interest_Less Interested  \\\n",
       "0                0            1                         1   \n",
       "1                0            1                         1   \n",
       "2                1            0                         0   \n",
       "3                0            1                         0   \n",
       "4                1            0                         0   \n",
       "..             ...          ...                       ...   \n",
       "995              1            0                         0   \n",
       "996              1            0                         1   \n",
       "997              0            1                         1   \n",
       "998              0            1                         0   \n",
       "999              0            1                         0   \n",
       "\n",
       "     interest_Not Interested  interest_Quiet Interested  interest_Uncertain  \\\n",
       "0                          0                          0                   0   \n",
       "1                          0                          0                   0   \n",
       "2                          0                          0                   0   \n",
       "3                          0                          0                   0   \n",
       "4                          0                          0                   0   \n",
       "..                       ...                        ...                 ...   \n",
       "995                        0                          0                   0   \n",
       "996                        0                          0                   0   \n",
       "997                        0                          0                   0   \n",
       "998                        0                          0                   1   \n",
       "999                        0                          1                   0   \n",
       "\n",
       "     interest_Very Interested  residence_Rural  residence_Urban  \n",
       "0                           0                0                1  \n",
       "1                           0                0                1  \n",
       "2                           1                0                1  \n",
       "3                           1                1                0  \n",
       "4                           1                0                1  \n",
       "..                        ...              ...              ...  \n",
       "995                         1                1                0  \n",
       "996                         0                1                0  \n",
       "997                         0                0                1  \n",
       "998                         0                1                0  \n",
       "999                         0                0                1  \n",
       "\n",
       "[1000 rows x 19 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[5] = pandas.read_csv(datasets_files[5])\n",
    "datasets[5] = datasets[5].dropna(axis=0)\n",
    "\n",
    "# Transform categorical data into many binary data \n",
    "datasets[5] = pandas.get_dummies(datasets[5])\n",
    "\n",
    "# Define target column\n",
    "datasets[5] = datasets[5].rename(columns={'in_college' : 'target'})\n",
    "\n",
    "datasets[5][\"target\"] = datasets[5][\"target\"].astype('uint8')\n",
    "\n",
    "datasets[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phishing - dataset[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UsingIP</th>\n",
       "      <th>LongURL</th>\n",
       "      <th>ShortURL</th>\n",
       "      <th>Symbol@</th>\n",
       "      <th>Redirecting//</th>\n",
       "      <th>PrefixSuffix-</th>\n",
       "      <th>SubDomains</th>\n",
       "      <th>HTTPS</th>\n",
       "      <th>DomainRegLen</th>\n",
       "      <th>Favicon</th>\n",
       "      <th>...</th>\n",
       "      <th>UsingPopupWindow</th>\n",
       "      <th>IframeRedirection</th>\n",
       "      <th>AgeofDomain</th>\n",
       "      <th>DNSRecording</th>\n",
       "      <th>WebsiteTraffic</th>\n",
       "      <th>PageRank</th>\n",
       "      <th>GoogleIndex</th>\n",
       "      <th>LinksPointingToPage</th>\n",
       "      <th>StatsReport</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11049</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11050</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11051</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11052</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11053</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11054 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       UsingIP  LongURL  ShortURL  Symbol@  Redirecting//  PrefixSuffix-  \\\n",
       "0            1        1         1        1              1             -1   \n",
       "1            1        0         1        1              1             -1   \n",
       "2            1        0         1        1              1             -1   \n",
       "3            1        0        -1        1              1             -1   \n",
       "4           -1        0        -1        1             -1             -1   \n",
       "...        ...      ...       ...      ...            ...            ...   \n",
       "11049        1       -1         1       -1              1              1   \n",
       "11050       -1        1         1       -1             -1             -1   \n",
       "11051        1       -1         1        1              1             -1   \n",
       "11052       -1       -1         1        1              1             -1   \n",
       "11053       -1       -1         1        1              1             -1   \n",
       "\n",
       "       SubDomains  HTTPS  DomainRegLen  Favicon  ...  UsingPopupWindow  \\\n",
       "0               0      1            -1        1  ...                 1   \n",
       "1              -1     -1            -1        1  ...                 1   \n",
       "2              -1     -1             1        1  ...                 1   \n",
       "3               1      1            -1        1  ...                -1   \n",
       "4               1      1            -1        1  ...                 1   \n",
       "...           ...    ...           ...      ...  ...               ...   \n",
       "11049           1      1            -1       -1  ...                -1   \n",
       "11050           1     -1            -1       -1  ...                -1   \n",
       "11051           1     -1            -1        1  ...                 1   \n",
       "11052          -1     -1             1       -1  ...                -1   \n",
       "11053          -1     -1             1        1  ...                 1   \n",
       "\n",
       "       IframeRedirection  AgeofDomain  DNSRecording  WebsiteTraffic  PageRank  \\\n",
       "0                      1           -1            -1               0        -1   \n",
       "1                      1            1            -1               1        -1   \n",
       "2                      1           -1            -1               1        -1   \n",
       "3                      1           -1            -1               0        -1   \n",
       "4                      1            1             1               1        -1   \n",
       "...                  ...          ...           ...             ...       ...   \n",
       "11049                 -1            1             1              -1        -1   \n",
       "11050                  1            1             1               1         1   \n",
       "11051                  1            1             1               1        -1   \n",
       "11052                  1            1             1               1        -1   \n",
       "11053                  1           -1             1              -1        -1   \n",
       "\n",
       "       GoogleIndex  LinksPointingToPage  StatsReport  target  \n",
       "0                1                    1            1       0  \n",
       "1                1                    0           -1       0  \n",
       "2                1                   -1            1       0  \n",
       "3                1                    1            1       1  \n",
       "4                1                   -1           -1       1  \n",
       "...            ...                  ...          ...     ...  \n",
       "11049            1                    1            1       1  \n",
       "11050            1                   -1            1       0  \n",
       "11051            1                    0            1       0  \n",
       "11052            1                    1            1       0  \n",
       "11053           -1                    1           -1       0  \n",
       "\n",
       "[11054 rows x 31 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[6] = pandas.read_csv(datasets_files[6])\n",
    "datasets[6] = datasets[6].dropna(axis=0)\n",
    "\n",
    "# Transform categorical data into many binary data \n",
    "datasets[6] = pandas.get_dummies(datasets[6])\n",
    "\n",
    "# Drop useless column\n",
    "datasets[6] = datasets[6].drop(columns=['Index'])\n",
    "\n",
    "# Define target column\n",
    "datasets[6] = datasets[6].rename(columns={'class' : 'target'})\n",
    "datasets[6][\"target\"].replace(to_replace = -1, value = 0, inplace=True)\n",
    "\n",
    "datasets[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoking - dataset[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height(cm)</th>\n",
       "      <th>weight(kg)</th>\n",
       "      <th>waist(cm)</th>\n",
       "      <th>eyesight(left)</th>\n",
       "      <th>eyesight(right)</th>\n",
       "      <th>hearing(left)</th>\n",
       "      <th>hearing(right)</th>\n",
       "      <th>systolic</th>\n",
       "      <th>relaxation</th>\n",
       "      <th>...</th>\n",
       "      <th>AST</th>\n",
       "      <th>ALT</th>\n",
       "      <th>Gtp</th>\n",
       "      <th>dental caries</th>\n",
       "      <th>target</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>oral_Y</th>\n",
       "      <th>tartar_N</th>\n",
       "      <th>tartar_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>155</td>\n",
       "      <td>60</td>\n",
       "      <td>81.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>170</td>\n",
       "      <td>60</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>165</td>\n",
       "      <td>70</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>155</td>\n",
       "      <td>60</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55687</th>\n",
       "      <td>40</td>\n",
       "      <td>170</td>\n",
       "      <td>65</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55688</th>\n",
       "      <td>45</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55689</th>\n",
       "      <td>55</td>\n",
       "      <td>160</td>\n",
       "      <td>50</td>\n",
       "      <td>68.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55690</th>\n",
       "      <td>60</td>\n",
       "      <td>165</td>\n",
       "      <td>60</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55691</th>\n",
       "      <td>55</td>\n",
       "      <td>160</td>\n",
       "      <td>65</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55692 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  height(cm)  weight(kg)  waist(cm)  eyesight(left)  \\\n",
       "0       40         155          60       81.3             1.2   \n",
       "1       40         160          60       81.0             0.8   \n",
       "2       55         170          60       80.0             0.8   \n",
       "3       40         165          70       88.0             1.5   \n",
       "4       40         155          60       86.0             1.0   \n",
       "...    ...         ...         ...        ...             ...   \n",
       "55687   40         170          65       75.0             0.9   \n",
       "55688   45         160          50       70.0             1.2   \n",
       "55689   55         160          50       68.5             1.0   \n",
       "55690   60         165          60       78.0             0.8   \n",
       "55691   55         160          65       85.0             0.9   \n",
       "\n",
       "       eyesight(right)  hearing(left)  hearing(right)  systolic  relaxation  \\\n",
       "0                  1.0            1.0             1.0     114.0        73.0   \n",
       "1                  0.6            1.0             1.0     119.0        70.0   \n",
       "2                  0.8            1.0             1.0     138.0        86.0   \n",
       "3                  1.5            1.0             1.0     100.0        60.0   \n",
       "4                  1.0            1.0             1.0     120.0        74.0   \n",
       "...                ...            ...             ...       ...         ...   \n",
       "55687              0.9            1.0             1.0     110.0        68.0   \n",
       "55688              1.2            1.0             1.0     101.0        62.0   \n",
       "55689              1.2            1.0             1.0     117.0        72.0   \n",
       "55690              1.0            1.0             1.0     133.0        76.0   \n",
       "55691              0.7            1.0             1.0     124.0        75.0   \n",
       "\n",
       "       ...   AST   ALT   Gtp  dental caries  target  gender_F  gender_M  \\\n",
       "0      ...  18.0  19.0  27.0              0       0         1         0   \n",
       "1      ...  22.0  19.0  18.0              0       0         1         0   \n",
       "2      ...  21.0  16.0  22.0              0       1         0         1   \n",
       "3      ...  19.0  26.0  18.0              0       0         0         1   \n",
       "4      ...  16.0  14.0  22.0              0       0         1         0   \n",
       "...    ...   ...   ...   ...            ...     ...       ...       ...   \n",
       "55687  ...  14.0   7.0  10.0              1       0         1         0   \n",
       "55688  ...  20.0  12.0  14.0              0       0         1         0   \n",
       "55689  ...  17.0  11.0  12.0              0       0         1         0   \n",
       "55690  ...  20.0  19.0  18.0              0       0         0         1   \n",
       "55691  ...  26.0  29.0  41.0              0       1         0         1   \n",
       "\n",
       "       oral_Y  tartar_N  tartar_Y  \n",
       "0           1         0         1  \n",
       "1           1         0         1  \n",
       "2           1         1         0  \n",
       "3           1         0         1  \n",
       "4           1         1         0  \n",
       "...       ...       ...       ...  \n",
       "55687       1         0         1  \n",
       "55688       1         0         1  \n",
       "55689       1         1         0  \n",
       "55690       1         1         0  \n",
       "55691       1         0         1  \n",
       "\n",
       "[55692 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[7] = pandas.read_csv(datasets_files[7])\n",
    "datasets[7] = datasets[7].dropna(axis=0)\n",
    "\n",
    "# Transform categorical data into many binary data \n",
    "datasets[7] = pandas.get_dummies(datasets[7])\n",
    "\n",
    "# Drop useless column\n",
    "datasets[7] = datasets[7].drop(columns=['ID'])\n",
    "\n",
    "# Define target column\n",
    "datasets[7] = datasets[7].rename(columns={'smoking' : 'target'})\n",
    "\n",
    "datasets[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social network ads - dataset[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>target</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age  EstimatedSalary  target  Gender_Female  Gender_Male\n",
       "0     19            19000       0              0            1\n",
       "1     35            20000       0              0            1\n",
       "2     26            43000       0              1            0\n",
       "3     27            57000       0              1            0\n",
       "4     19            76000       0              0            1\n",
       "..   ...              ...     ...            ...          ...\n",
       "395   46            41000       1              1            0\n",
       "396   51            23000       1              0            1\n",
       "397   50            20000       1              1            0\n",
       "398   36            33000       0              0            1\n",
       "399   49            36000       1              1            0\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load data and drop empty rows\n",
    "datasets[8] = pandas.read_csv(datasets_files[8])\n",
    "datasets[8] = datasets[8].dropna(axis=0)\n",
    "\n",
    "# Transform categorical data into many binary data \n",
    "datasets[8] = pandas.get_dummies(datasets[8])\n",
    "\n",
    "# Drop useless column\n",
    "datasets[8] = datasets[8].drop(columns=['User ID'])\n",
    "\n",
    "# Define target column\n",
    "datasets[8] = datasets[8].rename(columns={'Purchased' : 'target'})\n",
    "\n",
    "datasets[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water quality - dataset[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aluminium</th>\n",
       "      <th>ammonia</th>\n",
       "      <th>arsenic</th>\n",
       "      <th>barium</th>\n",
       "      <th>cadmium</th>\n",
       "      <th>chloramine</th>\n",
       "      <th>chromium</th>\n",
       "      <th>copper</th>\n",
       "      <th>flouride</th>\n",
       "      <th>bacteria</th>\n",
       "      <th>...</th>\n",
       "      <th>lead</th>\n",
       "      <th>nitrates</th>\n",
       "      <th>nitrites</th>\n",
       "      <th>mercury</th>\n",
       "      <th>perchlorate</th>\n",
       "      <th>radium</th>\n",
       "      <th>selenium</th>\n",
       "      <th>silver</th>\n",
       "      <th>uranium</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.65</td>\n",
       "      <td>9.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054</td>\n",
       "      <td>16.08</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.007</td>\n",
       "      <td>37.75</td>\n",
       "      <td>6.78</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.32</td>\n",
       "      <td>21.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.002</td>\n",
       "      <td>5.28</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.65</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.003</td>\n",
       "      <td>32.26</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.01</td>\n",
       "      <td>14.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.008</td>\n",
       "      <td>4.24</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078</td>\n",
       "      <td>14.16</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.006</td>\n",
       "      <td>50.28</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.36</td>\n",
       "      <td>11.33</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.001</td>\n",
       "      <td>7.23</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.004</td>\n",
       "      <td>9.12</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.92</td>\n",
       "      <td>24.33</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.006</td>\n",
       "      <td>2.67</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117</td>\n",
       "      <td>6.74</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.003</td>\n",
       "      <td>16.90</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7991</th>\n",
       "      <td>0.05</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197</td>\n",
       "      <td>14.29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.005</td>\n",
       "      <td>3.57</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7992</th>\n",
       "      <td>0.05</td>\n",
       "      <td>24.22</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031</td>\n",
       "      <td>10.27</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1.48</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>0.09</td>\n",
       "      <td>6.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182</td>\n",
       "      <td>15.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.35</td>\n",
       "      <td>4.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7994</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>0.04</td>\n",
       "      <td>6.85</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182</td>\n",
       "      <td>15.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.35</td>\n",
       "      <td>4.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7996 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aluminium  ammonia  arsenic  barium  cadmium  chloramine  chromium  \\\n",
       "0          1.65     9.08     0.04    2.85    0.007        0.35      0.83   \n",
       "1          2.32    21.16     0.01    3.31    0.002        5.28      0.68   \n",
       "2          1.01    14.02     0.04    0.58    0.008        4.24      0.53   \n",
       "3          1.36    11.33     0.04    2.96    0.001        7.23      0.03   \n",
       "4          0.92    24.33     0.03    0.20    0.006        2.67      0.69   \n",
       "...         ...      ...      ...     ...      ...         ...       ...   \n",
       "7991       0.05     7.78     0.00    1.95    0.040        0.10      0.03   \n",
       "7992       0.05    24.22     0.02    0.59    0.010        0.45      0.02   \n",
       "7993       0.09     6.85     0.00    0.61    0.030        0.05      0.05   \n",
       "7994       0.01    10.00     0.01    2.00    0.000        2.00      0.00   \n",
       "7995       0.04     6.85     0.01    0.70    0.030        0.05      0.01   \n",
       "\n",
       "      copper  flouride  bacteria  ...   lead  nitrates  nitrites  mercury  \\\n",
       "0       0.17      0.05      0.20  ...  0.054     16.08      1.13    0.007   \n",
       "1       0.66      0.90      0.65  ...  0.100      2.01      1.93    0.003   \n",
       "2       0.02      0.99      0.05  ...  0.078     14.16      1.11    0.006   \n",
       "3       1.66      1.08      0.71  ...  0.016      1.41      1.29    0.004   \n",
       "4       0.57      0.61      0.13  ...  0.117      6.74      1.11    0.003   \n",
       "...      ...       ...       ...  ...    ...       ...       ...      ...   \n",
       "7991    0.03      1.37      0.00  ...  0.197     14.29      1.00    0.005   \n",
       "7992    0.02      1.48      0.00  ...  0.031     10.27      1.00    0.001   \n",
       "7993    0.02      0.91      0.00  ...  0.182     15.92      1.00    0.000   \n",
       "7994    0.09      0.00      0.00  ...  0.000      0.00      0.00    0.000   \n",
       "7995    0.03      1.00      0.00  ...  0.182     15.92      1.00    0.000   \n",
       "\n",
       "      perchlorate  radium  selenium  silver  uranium  target  \n",
       "0           37.75    6.78      0.08    0.34     0.02       1  \n",
       "1           32.26    3.21      0.08    0.27     0.05       1  \n",
       "2           50.28    7.07      0.07    0.44     0.01       0  \n",
       "3            9.12    1.72      0.02    0.45     0.05       1  \n",
       "4           16.90    2.41      0.02    0.06     0.02       1  \n",
       "...           ...     ...       ...     ...      ...     ...  \n",
       "7991         3.57    2.13      0.09    0.06     0.03       1  \n",
       "7992         1.48    1.11      0.09    0.10     0.08       1  \n",
       "7993         1.35    4.84      0.00    0.04     0.05       1  \n",
       "7994         0.00    0.00      0.00    0.00     0.00       1  \n",
       "7995         1.35    4.84      0.00    0.04     0.05       1  \n",
       "\n",
       "[7996 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data and drop empty rows\n",
    "datasets[9] = pandas.read_csv(datasets_files[9])\n",
    "datasets[9] = datasets[9].dropna(axis=0)\n",
    "\n",
    "# Define target column\n",
    "datasets[9] = datasets[9].rename(columns={'is_safe' : 'target'})\n",
    "\n",
    "datasets[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All columns except target\n",
    "X = [None] * 10\n",
    "# Target column\n",
    "Y = [None] * 10\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    X[i] = dataset.loc[:, dataset.columns != 'target'] \n",
    "    Y[i] = np.array(dataset.loc[:, dataset.columns == 'target']).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAT6klEQVR4nO3df7RlZX3f8feHHwpRZECuFGdGhkVIWWh0pFd+1LYhoBVozZA0oVCXUsPqQIpdsUkTgWZFU0NDWiNLV1LaMaBDCyIxWmZZiBJkxdoGcIaOIz8kjMhkZjLAFfkpSmD89o/zzPY43DtzB9jn3Jn7fq2119n7efbe53uGWfNhP88++6SqkCQJYK9xFyBJmjsMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBe12kjyQ5G3jrkPaExkK0i5KclKSTeOuQ+qDoaA9VpJ9xl3DXOafj6ZjKGh39ZYkdyd5NMknk+y37f/gk3wgyYPAJ5PsleTCJN9K8kiS65IcvO0kSf4kyYNJHk/ylSSvH+o7vb3Hk0k2J/l3SV4B3Ai8NslTbXntTEUm2TvJxe39n0yyJsni1vexJBuTPNHa/+HQcR9qtV7VjrsryeRQ/+Ikn0sy1T7XHw71/XKSe9qfzReTHD7UV0kuSHIfcN+L/8+gPY2hoN3Vu4B3AEcCPwX8Vmv/O8DBwOHAcuDfAGcAPwO8FngU+KOh89wIHAW8BrgDuHqo7wrgvKo6AHgD8OWq+h5wGvA3VfXKtvzNDur8NeBs4HTgVcAvA0+3vq8BS1u91wB/kmS/oWN/DrgWWACsAv4QBkEDfAHYACwBFrb9SLIMuBj4BWAC+N/Ap7er6QzgeOCYHdSt+aqqXFx2qwV4ADh/aPt04FvAScDfAvsN9d0DnDK0fRjwLLDPNOddABRwYNv+a+A84FXb7XcSsGmWtd4LLJvlvo8Cb2rrHwL+fKjvGOD7bf1EYGqGz3AjcO7Q9l4MQujwtl3AyeP+b+gydxevFLS72ji0voHBVQDAVFX9YKjvcODzSR5L8hiDkNgKHNqGdi5tQztPMAgbgEPa6z9jEDgbkvxFkhNfQJ2LGQTW87ThqHva0NVjwIFD7w3w4ND608B+bR5gMbChqp6b5rSHAx8b+rzfBcLgamKbjdMcJwEOH2n3tXho/XXAtiGc7Z8FvxE4raoWDC37VdVm4F8Ay4C3MfgHeUk7JgBV9bWqWsZgaOl/AtfN8B47spHBENePafMHvwmcCRxUVQuAx7e99yzO+boZJoo3MhjyGv68+1fV/x3ax+fla0aGgnZXFyRZ1CaN/z3wmRn2+6/AJdsmW5NMtHF3gAOAZ4BHgJ8A/uO2g5K8LMm7khxYVc8CTwA/bN0PAa9OcuAs6vxj4MNJjsrAG5O8ur33c7RhoCS/zWDOYTZuB7YAlyZ5RZtkf+vQ571o24R5kgOT/NIszysZCtptXQN8CbifwfDM786w38cYTNJ+KcmTwK0MJlkBrmIw9LQZuLv1DXs38EAbWjqfweQ2VfVNBpO397dhmhnvPgI+yuAK40sMguUKYH/gi8CfAX/VavgBsxzWqaqtwDuBn2Qw77EJ+Oet7/PA7wPXtrrvZDAxLs1KqrySlCQNeKUgSeoYCtKLlOTGoS+yDS8Xj7s2aVc5fCRJ6uzWzz455JBDasmSJeMuQ5J2K2vWrPlOVU1M17dbh8KSJUtYvXr1uMuQpN1Kkg0z9TmnIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnq7NbfaH4p/L3fuGrcJWgOWvOf3zPuEqSx6O1Kof0a1O1Jvp7kriS/09o/leTbSda2ZWlrT5KPJ1mfZF2SY/uqTZI0vT6vFJ4BTq6qp5LsC3w1yY2t7zeq6rPb7X8acFRbjgcu50e/kCVJGoHerhRq4Km2uW9bdvSc7mXAVe24W4EFSQ7rqz5J0vP1OtGcZO8ka4GHgZuq6rbWdUkbIrosyctb20J+/DdqN7W27c+5PMnqJKunpqb6LF+S5p1eQ6GqtlbVUmARcFySNwAXAUcDbwEOBj6wi+dcUVWTVTU5MTHt48AlSS/QSG5JrarHgFuAU6tqSxsiegb4JHBc220zsHjosEWtTZI0In3efTSRZEFb3x94O/DNbfMESQKcAdzZDlkFvKfdhXQC8HhVbemrPknS8/V599FhwMokezMIn+uq6gtJvpxkAgiwFji/7X8DcDqwHngaeG+PtUmSptFbKFTVOuDN07SfPMP+BVzQVz2SpJ3zMReSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnq9BYKSfZLcnuSrye5K8nvtPYjktyWZH2SzyR5WWt/edte3/qX9FWbJGl6fV4pPAOcXFVvApYCpyY5Afh94LKq+kngUeDctv+5wKOt/bK2nyRphHoLhRp4qm3u25YCTgY+29pXAme09WVtm9Z/SpL0VZ8k6fl6nVNIsneStcDDwE3At4DHquq5tssmYGFbXwhsBGj9jwOvnuacy5OsTrJ6amqqz/Ilad7pNRSqamtVLQUWAccBR78E51xRVZNVNTkxMfFiTydJGjKSu4+q6jHgFuBEYEGSfVrXImBzW98MLAZo/QcCj4yiPknSQJ93H00kWdDW9wfeDtzDIBx+se12DnB9W1/Vtmn9X66q6qs+SdLz7bPzXV6ww4CVSfZmED7XVdUXktwNXJvkd4H/B1zR9r8C+O9J1gPfBc7qsTZJ0jR6C4WqWge8eZr2+xnML2zf/gPgl/qqR5K0c36jWZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSR1DQZLUMRQkSZ3eQiHJ4iS3JLk7yV1JfrW1fyjJ5iRr23L60DEXJVmf5N4k7+irNknS9Pbp8dzPAb9eVXckOQBYk+Sm1ndZVX1keOckxwBnAa8HXgv8eZKfqqqtPdYoSRrS25VCVW2pqjva+pPAPcDCHRyyDLi2qp6pqm8D64Hj+qpPkvR8I5lTSLIEeDNwW2t6X5J1Sa5MclBrWwhsHDpsE9OESJLlSVYnWT01NdVn2ZI07/QeCkleCfwp8P6qegK4HDgSWApsAf5gV85XVSuqarKqJicmJl7qciVpXus1FJLsyyAQrq6qzwFU1UNVtbWqfgh8gh8NEW0GFg8dvqi1SZJGpM+7jwJcAdxTVR8daj9saLefB+5s66uAs5K8PMkRwFHA7X3VJ0l6vj7vPnor8G7gG0nWtraLgbOTLAUKeAA4D6Cq7kpyHXA3gzuXLvDOI0kard5Coaq+CmSarht2cMwlwCV91SRJ2jG/0SxJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqROn7+8JulF+Ov/8NPjLkFz0Ot++xu9nn+nVwrt95J32iZJ2v3NZvjoT6dp++xLXYgkafxmHD5KcjTweuDAJL8w1PUqYL++C5Mkjd6OrhT+LvBPgQXAO4eWY4F/tbMTJ1mc5JYkdye5K8mvtvaDk9yU5L72elBrT5KPJ1mfZF2SY1/kZ5Mk7aIZrxSq6nrg+iQnVtVfvoBzPwf8elXdkeQAYE2Sm4B/CdxcVZcmuRC4EPgAcBpwVFuOBy5vr5KkEZnNnMIjSW5OcidAkjcm+a2dHVRVW6rqjrb+JHAPsBBYBqxsu60Ezmjry4CrauBWYEGSw3bp00iSXpTZhMIngIuAZwGqah1w1q68SZIlwJuB24BDq2pL63oQOLStLwQ2Dh22qbVtf67lSVYnWT01NbUrZUiSdmI2ofATVXX7dm3PzfYNkrySwR1M76+qJ4b7qqqAmu252jErqmqyqiYnJiZ25VBJ0k7MJhS+k+RI2j/eSX4R2LLjQwaS7MsgEK6uqs+15oe2DQu114db+2Zg8dDhi1qbJGlEZhMKFwD/DTg6yWbg/cCv7OygJAGuAO6pqo8Oda0Czmnr5wDXD7W/p92FdALw+NAwkyRpBHb6mIuquh94W5JXAHu1SePZeCvwbuAbSda2touBS4HrkpwLbADObH03AKcD64GngffO9kNIkl4aOw2FJL+23TbA48Caqlo703FV9VUgM3SfMs3+xeCqRJI0JrMZPpoEzmdwJ9BC4DzgVOATSX6zx9okSSM2m6ekLgKOraqnAJJ8EPhfwD8C1gD/qb/yJEmjNJsrhdcAzwxtP8vguwbf365dkrSbm82VwtXAbUm23SX0TuCaNvF8d2+VSZJGboeh0G4r/RRwI4O7iQDOr6rVbf1d/ZUmSRq1HYZCVVWSG6rqp4HVO9pXkrT7m82cwh1J3tJ7JZKksZvNnMLxwLuSbAC+x+C7B1VVb+y1MknSyM0mFN7RexWSpDlhNo+52ACQ5DX4M5yStEfb6ZxCkp9Lch/wbeAvgAcY3I0kSdrDzGai+cPACcBfVdURDJ5bdGuvVUmSxmI2ofBsVT0C7JVkr6q6hcHzkCRJe5jZTDQ/1n497SvA1UkeBp7qtyxJ0jjMJhS+zuD3Df4tg28wHwi8ss+iJEnjMZtQ+Nmq+iHwQ2AlQJJ1vVYlSRqLGUMhya8A/xo4crsQOAD4P30XJkkavR1dKVzD4NbT3wMuHGp/sqq+22tVkqSxmDEUqupxBj+7efboypEkjdNsbkmVJM0TvYVCkiuTPJzkzqG2DyXZnGRtW04f6rsoyfok9ybxeUuSNAZ9Xil8Cjh1mvbLqmppW24ASHIMcBbw+nbMf0myd4+1SZKm0VsoVNVXgNlOSC8Drq2qZ6rq28B64Li+apMkTW8ccwrvS7KuDS8d1NoWAhuH9tnU2p4nyfIkq5Osnpqa6rtWSZpXRh0KlwNHAkuBLcAf7OoJqmpFVU1W1eTExMRLXJ4kzW8jDYWqeqiqtrZvSH+CHw0RbQYWD+26qLVJkkZopKGQ5LChzZ8Htt2ZtAo4K8nLkxwBHAXcPsraJEmze/bRC5Lk08BJwCFJNgEfBE5KshQoBj/Wcx5AVd2V5DrgbuA54IKq2tpXbZKk6fUWClU13Tehr9jB/pcAl/RVjyRp5/xGsySpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjqGgiSpYyhIkjq9hUKSK5M8nOTOobaDk9yU5L72elBrT5KPJ1mfZF2SY/uqS5I0sz6vFD4FnLpd24XAzVV1FHBz2wY4DTiqLcuBy3usS5I0g95Coaq+Anx3u+ZlwMq2vhI4Y6j9qhq4FViQ5LC+apMkTW/UcwqHVtWWtv4gcGhbXwhsHNpvU2t7niTLk6xOsnpqaqq/SiVpHhrbRHNVFVAv4LgVVTVZVZMTExM9VCZJ89eoQ+GhbcNC7fXh1r4ZWDy036LWJkkaoVGHwirgnLZ+DnD9UPt72l1IJwCPDw0zSZJGZJ++Tpzk08BJwCFJNgEfBC4FrktyLrABOLPtfgNwOrAeeBp4b191SZJm1lsoVNXZM3SdMs2+BVzQVy2SpNnxG82SpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnq7DOON03yAPAksBV4rqomkxwMfAZYAjwAnFlVj46jPkmar8Z5pfCzVbW0qibb9oXAzVV1FHBz25YkjdBcGj5aBqxs6yuBM8ZXiiTNT+MKhQK+lGRNkuWt7dCq2tLWHwQOne7AJMuTrE6yempqahS1StK8MZY5BeAfVNXmJK8BbkryzeHOqqokNd2BVbUCWAEwOTk57T6SpBdmLFcKVbW5vT4MfB44DngoyWEA7fXhcdQmSfPZyEMhySuSHLBtHfjHwJ3AKuCctts5wPWjrk2S5rtxDB8dCnw+ybb3v6aq/izJ14DrkpwLbADOHENtkjSvjTwUqup+4E3TtD8CnDLqeiRJPzKXbkmVJI2ZoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6sy5UEhyapJ7k6xPcuG465Gk+WROhUKSvYE/Ak4DjgHOTnLMeKuSpPljToUCcBywvqrur6q/Ba4Flo25JkmaN/YZdwHbWQhsHNreBBw/vEOS5cDytvlUkntHVNt8cAjwnXEXMRfkI+eMuwT9OP9ubvPBvBRnOXymjrkWCjtVVSuAFeOuY0+UZHVVTY67Dml7/t0cnbk2fLQZWDy0vai1SZJGYK6FwteAo5IckeRlwFnAqjHXJEnzxpwaPqqq55K8D/gisDdwZVXdNeay5hOH5TRX+XdzRFJV465BkjRHzLXhI0nSGBkKkqSOoTDPJdmaZG2Srye5I8nfH3dNEkCSSvI/hrb3STKV5AvjrGtPN6cmmjUW36+qpQBJ3gH8HvAzY61IGvge8IYk+1fV94G34y3qvfNKQcNeBTw67iKkITcA/6Stnw18eoy1zAuGgvZvw0ffBP4Y+PC4C5KGXAuclWQ/4I3AbWOuZ4/n8JGGh49OBK5K8obyXmXNAVW1LskSBlcJN4y5nHnBKwV1quovGTx4bGLctUhDVgEfwaGjkfBKQZ0kRzP4Jvkj465FGnIl8FhVfSPJSWOuZY9nKGj/JGvbeoBzqmrrGOuRfkxVbQI+Pu465gsfcyFJ6jinIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnq/H8ahDX/QojMKwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAS4ElEQVR4nO3df7SdVX3n8fcHIv6AkYBcMpiAYSQjalWgEXE5Oq2ZWqBWGKtWly2RYSZjF53R4mqlXbPK6NhWx3aorungRHEMrU6hVAeWZSxMpNbOEmqCGH7pEFGaxEDCj6QgrYJ854+zs3sIN+GCee5Jct+vtc46+9l7n+d8b9bN+dz9POc5J1WFJEkAB0y6AEnS3sNQkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEhAkk8l+UCSVyf55gwf844kfzV0bdJsMhSkMVX15ap6wdDPY6Bob2UoSJI6Q0FzUpITk9yQ5IEklwLPaP0/kWTj2Lzzk3yrzbs1yb98/K7yX5NsT/KNJMvGBg5NcnGSzUk2tcNTByZ5IfAx4JVJHkyyrc1/epLfTfI3Se5O8rEkz2xjRyT5fJJtSe5L8uUk/v/VHucvleacJAcB/wv4Q+Bw4E+An9vF9G8BrwYOBd4H/FGSo8bGX9HmHAFcAHw2yeFt7FPAI8BxwInA64B/XVW3Ae8EvlJVh1TV/Db/g8A/BU5oj1kI/GYbew+wEZgCFgC/AfgZNdrjDAXNRacATwN+v6oerqrLga9ON7Gq/qSqvltVj1bVpcDtwMljU7aM7edS4JvAzyRZAJwOvLuqvldVW4ALgbdO9zxJAqwAfqWq7quqB4DfHpv/MHAU8Lz2XF8uP7hMA5g36QKkCXgusGmnF9U7p5uY5CzgPGBx6zqE0apgh+n281zgeYyCZ/Po9R4Y/RG2YRc1TQHPAtaOzQ9wYGt/GPiPwNVtfGVVfXBXP6D0VLlS0Fy0GViYsVdf4JidJyV5HvBx4JeB57TDPDczerHeYbr9fJfRi//3gSOqan67PbuqXtzm7fxX/j3A3wEvHpt/aFUdAlBVD1TVe6rqnwBvAM4bP38h7SmGguairzA61v/vkzwtyRt57CGhHQ5m9OK9FSDJ2cCP7TTnyLH9vBl4IXBVVW0GrgZ+L8mzkxyQ5PlJ/nl73N3AonZ+g6p6lFEAXZjkyPZ8C5P8dGu/PslxLYC2Az8EHt0z/xzSPzAUNOdU1Q+ANwLvAO4Dfh747DTzbgV+j1GI3A28BPi/O027HljC6C/93wLeVFX3trGzgIOAW4H7gcsZnRcA+CJwC3BXknta33uB9cB1Sf4W+D/AjmsmlrTtB1s9/62qrn1K/wDSbsRzVZKkHVwpSJI6Q0GS1BkKkqTOUJAkdfv0xWtHHHFELV68eNJlSNI+Ze3atfdU1dR0Y/t0KCxevJg1a9ZMugxJ2qckmfYKfvDwkSRpjKEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEndPn1F857w4796yaRL0F5o7YfPmnQJ0kS4UpAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1g4ZCkvlJLk/yjSS3JXllksOTXJPk9nZ/WJubJB9Nsj7JuiQnDVmbJOnxhl4pfAT4QlUdD7wMuA04H1hdVUuA1W0b4DRgSbutAC4auDZJ0k4GC4UkhwKvAS4GqKofVNU24AxgVZu2Cjiztc8ALqmR64D5SY4aqj5J0uMNuVI4FtgK/I8kX0vyiSQHAwuqanObcxewoLUXAhvGHr+x9T1GkhVJ1iRZs3Xr1gHLl6S5Z8hQmAecBFxUVScC3+MfDhUBUFUF1JPZaVWtrKqlVbV0ampqjxUrSRo2FDYCG6vq+rZ9OaOQuHvHYaF2v6WNbwKOHnv8otYnSZolg4VCVd0FbEjygta1DLgVuBJY3vqWA1e09pXAWe1dSKcA28cOM0mSZsHQX7Lz74BPJzkIuAM4m1EQXZbkHOBO4C1t7lXA6cB64KE2V5I0iwYNhaq6EVg6zdCyaeYWcO6Q9UiSds8rmiVJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYOGQpLvJLkpyY1J1rS+w5Nck+T2dn9Y60+SjyZZn2RdkpOGrE2S9HizsVL4yao6oaqWtu3zgdVVtQRY3bYBTgOWtNsK4KJZqE2SNGYSh4/OAFa19irgzLH+S2rkOmB+kqMmUJ8kzVlDh0IBVydZm2RF61tQVZtb+y5gQWsvBDaMPXZj65MkzZJ5A+//n1XVpiRHAtck+cb4YFVVknoyO2zhsgLgmGOO2XOVSpKGXSlU1aZ2vwX4HHAycPeOw0Ltfkubvgk4euzhi1rfzvtcWVVLq2rp1NTUkOVL0pwzWCgkOTjJP9rRBl4H3AxcCSxv05YDV7T2lcBZ7V1IpwDbxw4zSZJmwZCHjxYAn0uy43k+U1VfSPJV4LIk5wB3Am9p868CTgfWAw8BZw9YmyRpGoOFQlXdAbxsmv57gWXT9Bdw7lD1SJKemFc0S5I6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUjd4KCQ5MMnXkny+bR+b5Pok65NcmuSg1v/0tr2+jS8eujZJ0mPNxkrhXcBtY9sfAi6squOA+4FzWv85wP2t/8I2T5I0iwYNhSSLgJ8BPtG2A7wWuLxNWQWc2dpntG3a+LI2X5I0S4ZeKfw+8GvAo237OcC2qnqkbW8EFrb2QmADQBvf3uY/RpIVSdYkWbN169YBS5ekuWewUEjyemBLVa3dk/utqpVVtbSqlk5NTe3JXUvSnDdvwH2/CnhDktOBZwDPBj4CzE8yr60GFgGb2vxNwNHAxiTzgEOBewesT5K0k8FWClX161W1qKoWA28FvlhVbweuBd7Upi0HrmjtK9s2bfyLVVVD1SdJerxJXKfwXuC8JOsZnTO4uPVfDDyn9Z8HnD+B2iRpThvy8FFXVX8B/EVr3wGcPM2cvwfePBv1SJKm5xXNkqTuCUMhybEz6ZMk7ftmslL402n6Lp+mT5K0j9vlOYUkxwMvBg5N8saxoWczeoupJGk/s7sTzS8AXg/MB352rP8B4N8MWJMkaUJ2GQpVdQVwRZJXVtVXZrEmSdKEzOScwr1JVie5GSDJS5P8h4HrkiRNwExC4ePArwMPA1TVOkZXKEuS9jMzCYVnVdVf79T3yLQzJUn7tJmEwj1Jng8UQJI3AZsHrUqSNBEz+ZiLc4GVwPFJNgHfBn5h0KokSRPxhKHQPqvoXyQ5GDigqh4YvixJ0iQ8YSgkOW+nbRh9K9raqrpxmLIkSZMwk3MKS4F3Mvq6zIXAvwVOBT6e5NcGrE2SNMtmck5hEXBSVT0IkOQC4M+A1wBrgf88XHmSpNk0k5XCkcD3x7YfBhZU1d/t1C9J2sfNZKXwaeD6JDu+NvNngc+0E8+3DlaZJGnW7TYUMjqr/CngfwOvat3vrKo1rf324UqTJM223YZCVVWSq6rqJcCa3c2VJO37ZnJO4YYkLx+8EknSxM3knMIrgLcnuRP4HhBGi4iXDlqZJGnWzSQUfnrwKiRJe4WZfMzFnQBJjsSv4ZSk/doTnlNI8oYktzP6ILwvAd9h9G6kJ3rcM5L8dZKvJ7klyfta/7FJrk+yPsmlSQ5q/U9v2+vb+OIf5QeTJD15MznR/J+AU4D/V1XHAsuA62bwuO8Dr62qlwEnAKcmOQX4EHBhVR0H3A+c0+afA9zf+i9s8yRJs2gmofBwVd0LHJDkgKq6ltHnIe1WjTzYNp/WbgW8Fri89a8CzmztM9o2bXxZu05CkjRLZhIK25IcAvwl8OkkHwEefILHAJDkwCQ3AluAa4BvAduqasc3t21k9CF7tPsNAG18O/Ccafa5IsmaJGu2bt06kzIkSTM0k1D4OvAQ8CvAFxi9sH9jJjuvqh9W1QmMPlTvZOD4p1bmY/a5sqqWVtXSqampH3V3kqQxM3lL6k9W1aPAo7TDO0nWPZknqaptSa4FXgnMTzKvrQYWAZvatE3A0cDGJPOAQ4F7n8zzSJJ+NLtcKST5pSQ3MfoaznVjt28DTxgKSaaSzG/tZwI/BdwGXAu8qU1bDuz4oL0r2zZt/ItVVU/hZ5IkPUW7Wyl8htFbT38HOH+s/4Gqum8G+z4KWJXkQEbhc1lVfT7JrcAfJ/kA8DXg4jb/YuAPk6wH7gPe+uR+FEnSj2qXoVBV2xmd7H3bU9lxVa0DTpym/w5G5xd27v974M1P5bkkSXvGTE40S5LmCENBktQZCpKkzlCQJHWGgiSpMxQkSd1MrmiWNAF/8/6XTLoE7YWO+c2bBt2/KwVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gYLhSRHJ7k2ya1JbknyrtZ/eJJrktze7g9r/Uny0STrk6xLctJQtUmSpjfkSuER4D1V9SLgFODcJC8CzgdWV9USYHXbBjgNWNJuK4CLBqxNkjSNwUKhqjZX1Q2t/QBwG7AQOANY1aatAs5s7TOAS2rkOmB+kqOGqk+S9Hizck4hyWLgROB6YEFVbW5DdwELWnshsGHsYRtb3877WpFkTZI1W7duHa5oSZqDBg+FJIcAfwq8u6r+dnysqgqoJ7O/qlpZVUuraunU1NQerFSSNGgoJHkao0D4dFV9tnXfveOwULvf0vo3AUePPXxR65MkzZIh330U4GLgtqr6L2NDVwLLW3s5cMVY/1ntXUinANvHDjNJkmbBvAH3/SrgF4GbktzY+n4D+CBwWZJzgDuBt7Sxq4DTgfXAQ8DZA9YmSZrGYKFQVX8FZBfDy6aZX8C5Q9UjSXpiXtEsSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkbLBSSfDLJliQ3j/UdnuSaJLe3+8Naf5J8NMn6JOuSnDRUXZKkXRtypfAp4NSd+s4HVlfVEmB12wY4DVjSbiuAiwasS5K0C4OFQlX9JXDfTt1nAKtaexVw5lj/JTVyHTA/yVFD1SZJmt5sn1NYUFWbW/suYEFrLwQ2jM3b2PokSbNoYieaq6qAerKPS7IiyZoka7Zu3TpAZZI0d812KNy947BQu9/S+jcBR4/NW9T6HqeqVlbV0qpaOjU1NWixkjTXzHYoXAksb+3lwBVj/We1dyGdAmwfO8wkSZol84bacZL/CfwEcESSjcAFwAeBy5KcA9wJvKVNvwo4HVgPPAScPVRdkqRdGywUquptuxhaNs3cAs4dqhZJ0sx4RbMkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1e1UoJDk1yTeTrE9y/qTrkaS5Zq8JhSQHAn8AnAa8CHhbkhdNtipJmlv2mlAATgbWV9UdVfUD4I+BMyZckyTNKfMmXcCYhcCGse2NwCt2npRkBbCibT6Y5JuzUNtccQRwz6SL2Bvkd5dPugQ9lr+bO1yQPbGX5+1qYG8KhRmpqpXAyknXsT9Ksqaqlk66Dmln/m7Onr3p8NEm4Oix7UWtT5I0S/amUPgqsCTJsUkOAt4KXDnhmiRpTtlrDh9V1SNJfhn4c+BA4JNVdcuEy5prPCynvZW/m7MkVTXpGiRJe4m96fCRJGnCDAVJUmcoSJI6Q0GS1BkKc1CSxUluS/LxJLckuTrJM5OckOS6JOuSfC7JYZOuVXNDkvcneffY9m8leVeSX03y1fY7+b42dnCSP0vy9SQ3J/n5iRW+HzIU5q4lwB9U1YuBbcDPAZcA762qlwI3ARdMrjzNMZ8EzgJIcgCj65TuYvR7ejJwAvDjSV4DnAp8t6peVlU/BnxhIhXvpwyFuevbVXVja68Fng/Mr6ovtb5VwGsmUZjmnqr6DnBvkhOB1wFfA14+1r4BOJ5RSNwE/FSSDyV5dVVtn0zV+6e95uI1zbrvj7V/CMyfUB3SDp8A3gH8Y0Yrh2XA71TVf995YpKTgNOBDyRZXVXvn81C92euFLTDduD+JK9u278IfGk386U97XOMDg29nNEnG/w58K+SHAKQZGGSI5M8F3ioqv4I+DBw0qQK3h+5UtC45cDHkjwLuAM4e8L1aA6pqh8kuRbYVlU/BK5O8kLgK0kAHgR+ATgO+HCSR4GHgV+aVM37Iz/mQtJeoZ1gvgF4c1XdPul65ioPH0mauPbVu+uB1QbCZLlSkCR1rhQkSZ2hIEnqDAVJUmcoSJI6Q0GS1P1/lKLvemeEkLsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEICAYAAACwDehOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQ4UlEQVR4nO3de7BdZXnH8e8P4h0FgZhiAoZKRgdHRZoq1tYbWoGKoQ5SHC0ZJ2Nqix0tTjVab21tvdSplxmrjcWKUy9QLUPGWltErGNH0OAFUGqJSppEJJFboVQFefrHfvO6CSdkg1lnn8P5fmb27LWed+13P4Ez53fWWnuvlapCkiSAfabdgCRp7jAUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCtIckOTpSbaOrV+V5FnT7EkLk6EgNUkqyRHT7kOaJkNBktQZCpq3khyd5OtJbkryj0nOTvKWNvbSJJuSXJdkQ5KH72GuL7bFbya5Ocnv3JN52msek+T89pprkryu1e+X5N1JftAe705yvwnm2yfJuiTfTXJtknOSHDg2flqSzW3sDeOHnvb0WmlXhoLmpST3Bc4FPgwcCHwc+O029kzgrcApwCHAZuATdzVfVT21LT6+qvarqrPvyTxJHgx8Dvgs8HDgCOCCNvwnwDHAUcDjgScCr5/gn/uHwEnA09qc1wPva+93JPA3wItaj/sDSyd5rTSjqvLhY949gKcC24CM1b4EvAU4E3jHWH0/4FZg+R7mLOCIsfW7PQ/wQuDruxn7LnDC2PpzgKva8tOBrWNjVwHPastXAMeOjR3S+lgEvBH4+NjYA4GfTvLaaf8/9DE3H4v2TrRIs+7hwLaqGr+i45axsa/tLFbVzUmuZfQX9FV38z3u7jyHMvrlv7v5No+tb261PXkEcG6S28dqPwOWtNfv/HdTVbe0Hid57bYJ3lsLjIePNF9dDSxNkrHaoe35B4x+GQKQ5EHAQdz9X4L3ZJ4twC9PMh9wWKvtyRbg+Ko6YOxx/6raxui/w7KxHh/QepzktdKdGAqar77M6C/elydZlGQVo2P0MDq/8JIkR7UTuX8JXFxVV+1hzmu44y/0ezLPp4FDkryynVh+cJInjc33+iSLkxzM6NDPP0zwb/0A8BdJHgHQXr+qjX0SODHJr7XzLG8GMuFrpTsxFDQvVdVPgecDa4AbgBcz+oX8k6r6HPAG4FOM/pJ+JHDqBNO+GTgryQ1JTrkn81TVTcCzgROBHwJXAs9ow28BNgKXApcxOjT1lgn6eg+wAfi3JDcBFwFPau/3LUYnkz/RerwZ2A78ZE+vlWaSOx6SleavJBcDH6iqv592L9OSZD9GIbmiqr4/5XY0D7mnoHkrydOS/FI7fLQaeByjj4IuKElOTPLAds7jnYz2Qq6ablearwwFzWePAr7J6C/jVwEnV9XVu9s4yW+0L6bd6XF33nRvzbMXrWJ0wvoHwArg1PIQgO4hDx9Jkjr3FCRJ3bz+8trBBx9cy5cvn3YbkjSvXHLJJT+qqsUzjc3rUFi+fDkbN26cdhuSNK8k2by7MQ8fSZI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJ3aCh0O4Ve1mSbyTZ2GoHtvvXXtmeH9rqSfLedj/cS5McPWRvkqQ7m409hWdU1VFVtbKtrwMuqKoVjO5du67Vj2d03ZYVwFrg/bPQmyRpzDQOH60CzmrLZzG6qfjO+kdq5CLggCSHTKE/SVqwhv5GczG6uUcBf1tV64ElY1ey/CGje8XC6L63W8Zeu7XV7nDVyyRrGe1JcNhhh/3CDf7KH3/kF55D9z6X/NVp026B//6zx067Bc1Bh73xskHnHzoUfr2qtiV5GHB+kv8cH6yqaoExsRYs6wFWrlzpJV4laS8a9PDRzpuDV9V24FxG99C9Zudhofa8vW2+jZ/feB1GNyP35uKSNIsGC4UkD0ry4J3LwG8ClzO6X+zqttlq4Ly2vAE4rX0K6Rjgxru6YYokae8b8vDREuDcJDvf52NV9dkkXwXOSbIG2Ayc0rb/DHACsAm4BXjJgL1JkmYwWChU1feAx89QvxY4doZ6AacP1Y8kac/8RrMkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWDh0KSfZN8Pcmn2/rhSS5OsinJ2Unu2+r3a+ub2vjyoXuTJN3RbOwpvAK4Ymz97cC7quoI4HpgTauvAa5v9Xe17SRJs2jQUEiyDPgt4O/aeoBnAp9sm5wFnNSWV7V12vixbXtJ0iwZek/h3cCrgdvb+kHADVV1W1vfCixty0uBLQBt/Ma2/R0kWZtkY5KNO3bsGLB1SVp4BguFJM8FtlfVJXtz3qpaX1Urq2rl4sWL9+bUkrTgLRpw7qcAz0tyAnB/4CHAe4ADkixqewPLgG1t+23AocDWJIuA/YFrB+xPkrSLwfYUquq1VbWsqpYDpwKfr6oXARcCJ7fNVgPnteUNbZ02/vmqqqH6kyTd2TS+p/Aa4IwkmxidMziz1c8EDmr1M4B1U+hNkha0IQ8fdVX1BeALbfl7wBNn2ObHwAtmox9J0sz8RrMkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWDhUKS+yf5SpJvJvlWkj9t9cOTXJxkU5Kzk9y31e/X1je18eVD9SZJmtmQewo/AZ5ZVY8HjgKOS3IM8HbgXVV1BHA9sKZtvwa4vtXf1baTJM2iwUKhRm5uq/dpjwKeCXyy1c8CTmrLq9o6bfzYJBmqP0nSnQ16TiHJvkm+AWwHzge+C9xQVbe1TbYCS9vyUmALQBu/EThoyP4kSXc0aChU1c+q6ihgGfBE4NG/6JxJ1ibZmGTjjh07ftHpJEljZuXTR1V1A3Ah8GTggCSL2tAyYFtb3gYcCtDG9weunWGu9VW1sqpWLl68eOjWJWlB2WMoJDl8ktoM2yxOckBbfgDwbOAKRuFwcttsNXBeW97Q1mnjn6+q2tP7SJL2nkn2FD41Q+2TM9R2dQhwYZJLga8C51fVp4HXAGck2cTonMGZbfszgYNa/Qxg3QTvIUnaixbtbiDJo4HHAPsnef7Y0EOA++9p4qq6FHjCDPXvMTq/sGv9x8ALJuhZkjSQ3YYC8CjgucABwIlj9ZuAlw7YkyRpSnYbClV1HnBekidX1ZdnsSdJ0pRMck7h2iQXJLkcIMnjkrx+4L4kSVMwSSh8EHgtcCv0cwWnDtmUJGk6JgmFB1bVV3ap3TbjlpKkeW2SUPhRkkcyum4RSU4Grh60K0nSVNzVp492Oh1YDzw6yTbg+8CLB+1KkjQVewyF9r2CZyV5ELBPVd00fFuSpGnYYygkOWOXdRhdwfSSqvrGMG1JkqZhknMKK4GXMbq09VLg94DjgA8mefWAvUmSZtkk5xSWAUfvvGFOkjcB/ww8FbgEeMdw7UmSZtMkewoPY3RrzZ1uBZZU1f/tUpckzXOT7Cl8FLg4yc5LXJ8IfKydeP72YJ1JkmbdXYZCu0fyh4F/AZ7Syi+rqo1t+UXDtSZJmm13GQpVVUk+U1WPBTbe1baSpPlvknMKX0vyq4N3IkmauknOKTwJeFGSzcD/AmG0E/G4QTuTJM26SULhOYN3IUmaEya5zMVmgCQPY4LbcEqS5q89nlNI8rwkVzK6EN6/A1cx+jSSJOleZpITzX8OHAP8V1UdDhwLXDRoV5KkqZgkFG6tqmuBfZLsU1UXMroekiTpXmaSE803JNkP+CLw0STbgZuHbUuSNA2ThMI3gVuAP2L0Deb9gf2GbEqSNB2ThMIzqup24HbgLIAklw7alSRpKnYbCkl+H/gD4JG7hMCDgf8YujFJ0uy7qz2FjzH66OlbgXVj9Zuq6rpBu5IkTcVuQ6GqbmR0280Xzl47kqRpmuQjqZKkBcJQkCR1hoIkqTMUJEmdoSBJ6gYLhSSHJrkwybeTfCvJK1r9wCTnJ7myPT+01ZPkvUk2Jbk0ydFD9SZJmtmQewq3Aa+qqiMZXWX19CRHMvrOwwVVtQK4gJ9/B+J4YEV7rAXeP2BvkqQZDBYKVXV1VX2tLd8EXAEsBVbRLpfRnk9qy6uAj9TIRcABSQ4Zqj9J0p3NyjmFJMuBJwAXA0uq6uo29ENgSVteCmwZe9nWVtt1rrVJNibZuGPHjuGalqQFaPBQaJfd/hTwyqr6n/Gxqiqg7s58VbW+qlZW1crFixfvxU4lSYOGQpL7MAqEj1bVP7XyNTsPC7Xn7a2+DTh07OXLWk2SNEuG/PRRgDOBK6rqr8eGNgCr2/Jq4Lyx+mntU0jHADeOHWaSJM2CSe6ncE89Bfhd4LIk32i11wFvA85JsgbYDJzSxj4DnABsYnRTn5cM2JskaQaDhUJVfQnIboaPnWH7Ak4fqh9J0p75jWZJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoGC4UkH0qyPcnlY7UDk5yf5Mr2/NBWT5L3JtmU5NIkRw/VlyRp94bcU/gwcNwutXXABVW1ArigrQMcD6xoj7XA+wfsS5K0G4OFQlV9Ebhul/Iq4Ky2fBZw0lj9IzVyEXBAkkOG6k2SNLPZPqewpKqubss/BJa05aXAlrHttrbanSRZm2Rjko07duwYrlNJWoCmdqK5qgqoe/C69VW1sqpWLl68eIDOJGnhmu1QuGbnYaH2vL3VtwGHjm23rNUkSbNotkNhA7C6La8Gzhurn9Y+hXQMcOPYYSZJ0ixZNNTEST4OPB04OMlW4E3A24BzkqwBNgOntM0/A5wAbAJuAV4yVF+SpN0bLBSq6oW7GTp2hm0LOH2oXiRJk/EbzZKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqTOUJAkdYaCJKkzFCRJnaEgSeoMBUlSZyhIkjpDQZLUGQqSpM5QkCR1hoIkqTMUJEmdoSBJ6gwFSVJnKEiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnqDAVJUmcoSJI6Q0GS1BkKkqRuToVCkuOSfCfJpiTrpt2PJC00cyYUkuwLvA84HjgSeGGSI6fblSQtLHMmFIAnApuq6ntV9VPgE8CqKfckSQvKomk3MGYpsGVsfSvwpF03SrIWWNtWb07ynVnobaE4GPjRtJuYC/LO1dNuQXfkz+ZOb8remOURuxuYS6EwkapaD6yfdh/3Rkk2VtXKafch7cqfzdkzlw4fbQMOHVtf1mqSpFkyl0Lhq8CKJIcnuS9wKrBhyj1J0oIyZw4fVdVtSV4O/CuwL/ChqvrWlNtaaDwsp7nKn81Zkqqadg+SpDliLh0+kiRNmaEgSeoMBXl5Ec1ZST6UZHuSy6fdy0JhKCxwXl5Ec9yHgeOm3cRCYijIy4tozqqqLwLXTbuPhcRQ0EyXF1k6pV4kTZmhIEnqDAV5eRFJnaEgLy8iqTMUFriqug3YeXmRK4BzvLyI5ookHwe+DDwqydYka6bd072dl7mQJHXuKUiSOkNBktQZCpKkzlCQJHWGgiSpMxQkSZ2hIEnq/h8O40kLFdMXtwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Type of evaluation\n",
    "scoring_choosed = [None] * 10\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    # Para plotar a proporção das classes, primeiro contamos os valores da coluna 'target' e transformamos em um frame\n",
    "    class_distribuition = pandas.DataFrame(dataset['target'].value_counts())\n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "    # Usamos o frame criado acima para plot a frequencia de cada classe no dataset\n",
    "    plot = seaborn.barplot(x=class_distribuition.index, y='target', data = class_distribuition)\n",
    "    plot.set_title(datasets_names[i])\n",
    "\n",
    "    total_sum = sum(class_distribuition['target'])\n",
    "    partition = total_sum/len(class_distribuition['target'])\n",
    "    for value in class_distribuition['target']:\n",
    "        if(0.9 * partition <= value <= 1.1 * partition):\n",
    "            scoring_choosed[i] = \"accuracy\" \n",
    "        else:\n",
    "            scoring_choosed[i] = \"balanced_accuracy\"\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importa metodos de classicacao\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instancia os classificador \n",
    "DTC = DecisionTreeClassifier()\n",
    "KNN = KNeighborsClassifier()\n",
    "GNB = GaussianNB()\n",
    "MLP = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC_parameters = {'criterion' : ['gini','entropy','log_loss'], 'random_state' : [42]}\n",
    "KNN_parameters = {'n_neighbors' : [1, 3, 5, 7, 9, 11, 13], 'weights' : ['uniform', 'distance']}\n",
    "GNB_parameters = {}\n",
    "MLP_parameters = {'hidden_layer_sizes' : [(5), (8), (15), (5, 3), (8, 5), (10, 5)], 'max_iter' : [3000], 'random_state' : [42]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_DTC = [None] * 10\n",
    "GS_KNN = [None] * 10\n",
    "GS_GNB = [None] * 10\n",
    "GS_MLP = [None] * 10\n",
    "\n",
    "for i, choosed in enumerate(scoring_choosed):\n",
    "    GS_DTC[i] = GridSearchCV(DTC, DTC_parameters, cv = 10, scoring = choosed)\n",
    "    GS_KNN[i] = GridSearchCV(KNN, KNN_parameters, cv = 10, scoring = choosed)\n",
    "    GS_GNB[i] = GridSearchCV(GNB, GNB_parameters, cv = 10, scoring = choosed)\n",
    "    GS_MLP[i] = GridSearchCV(MLP, MLP_parameters, cv = 10, scoring = choosed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# treina o classificador com o conjunto de treino\n",
    "for i in range(len(datasets)):\n",
    "    GS_DTC[i].fit(X[i], Y[i])\n",
    "    GS_KNN[i].fit(X[i], Y[i])\n",
    "    GS_GNB[i].fit(X[i], Y[i])\n",
    "    GS_MLP[i].fit(X[i], Y[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 219, in __call__\n",
      "    return self._score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 267, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py\", line 1365, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: pos_label=1 is not a valid label. It should be one of ['B', 'M']\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\eduar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011501</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>gini</td>\n",
       "      <td>42</td>\n",
       "      <td>{'criterion': 'gini', 'random_state': 42}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012599</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>entropy</td>\n",
       "      <td>42</td>\n",
       "      <td>{'criterion': 'entropy', 'random_state': 42}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011088</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>42</td>\n",
       "      <td>{'criterion': 'log_loss', 'random_state': 42}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.011501      0.001748         0.002597        0.000662   \n",
       "1       0.012599      0.001805         0.002601        0.000922   \n",
       "2       0.011088      0.000927         0.002307        0.000437   \n",
       "\n",
       "  param_criterion param_random_state  \\\n",
       "0            gini                 42   \n",
       "1         entropy                 42   \n",
       "2        log_loss                 42   \n",
       "\n",
       "                                          params  split0_test_score  \\\n",
       "0      {'criterion': 'gini', 'random_state': 42}                NaN   \n",
       "1   {'criterion': 'entropy', 'random_state': 42}                NaN   \n",
       "2  {'criterion': 'log_loss', 'random_state': 42}                NaN   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "\n",
       "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1                NaN                NaN                NaN                NaN   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "\n",
       "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                NaN              NaN             NaN                1  \n",
       "1                NaN              NaN             NaN                2  \n",
       "2                NaN              NaN             NaN                3  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heue = GridSearchCV(DTC, DTC_parameters, cv = 10, scoring = 'f1')\n",
    "heue.fit(X[1],Y[1])\n",
    "heue_results = pandas.DataFrame(heue.cv_results_)\n",
    "heue_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DTC = [None] * 10\n",
    "results_KNN = [None] * 10\n",
    "results_GNB = [None] * 10\n",
    "results_MLP = [None] * 10\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    results_DTC[i] = pandas.DataFrame(GS_DTC[i].cv_results_)\n",
    "    results_KNN[i] = pandas.DataFrame(GS_KNN[i].cv_results_)\n",
    "    results_GNB[i] = pandas.DataFrame(GS_GNB[i].cv_results_)\n",
    "    results_MLP[i] = pandas.DataFrame(GS_MLP[i].cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = ['params', 'mean_test_score','std_test_score', 'rank_test_score']\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    results_DTC[i] = results_DTC[i][view].sort_values(by='rank_test_score')\n",
    "    results_KNN[i] = results_KNN[i][view].sort_values(by='rank_test_score')\n",
    "    results_GNB[i] = results_GNB[i][view].sort_values(by='rank_test_score')\n",
    "    results_MLP[i] = results_MLP[i][view].sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para o dataset cs:\n",
      "\tA acurácia do Classificador DTC é: 69.93%\n",
      "\tA acurácia do Classificador KNN é: 66.99%\n",
      "\tA acurácia do Classificador GNB é: 73.03%\n",
      "\tA acurácia do Classificador MLP é: 74.07%\n",
      "\n",
      "Para o dataset breast_cancer:\n",
      "\tA acurácia do Classificador DTC é: 92.54%\n",
      "\tA acurácia do Classificador KNN é: 90.42%\n",
      "\tA acurácia do Classificador GNB é: 92.65%\n",
      "\tA acurácia do Classificador MLP é: 91.99%\n",
      "\n",
      "Para o dataset diabetes:\n",
      "\tA acurácia do Classificador DTC é: 94.72%\n",
      "\tA acurácia do Classificador KNN é: 92.97%\n",
      "\tA acurácia do Classificador GNB é: 56.77%\n",
      "\tA acurácia do Classificador MLP é: 93.11%\n",
      "\n",
      "Para o dataset driving_behavior:\n",
      "\tA acurácia do Classificador DTC é: 36.74%\n",
      "\tA acurácia do Classificador KNN é: 35.43%\n",
      "\tA acurácia do Classificador GNB é: 40.12%\n",
      "\tA acurácia do Classificador MLP é: 42.02%\n",
      "\n",
      "Para o dataset employee:\n",
      "\tA acurácia do Classificador DTC é: 77.69%\n",
      "\tA acurácia do Classificador KNN é: 70.98%\n",
      "\tA acurácia do Classificador GNB é: 67.09%\n",
      "\tA acurácia do Classificador MLP é: 64.50%\n",
      "\n",
      "Para o dataset go_to_college:\n",
      "\tA acurácia do Classificador DTC é: 83.10%\n",
      "\tA acurácia do Classificador KNN é: 67.10%\n",
      "\tA acurácia do Classificador GNB é: 72.40%\n",
      "\tA acurácia do Classificador MLP é: 50.00%\n",
      "\n",
      "Para o dataset phishing:\n",
      "\tA acurácia do Classificador DTC é: 96.09%\n",
      "\tA acurácia do Classificador KNN é: 95.89%\n",
      "\tA acurácia do Classificador GNB é: 64.44%\n",
      "\tA acurácia do Classificador MLP é: 93.36%\n",
      "\n",
      "Para o dataset smoking:\n",
      "\tA acurácia do Classificador DTC é: 79.57%\n",
      "\tA acurácia do Classificador KNN é: 77.54%\n",
      "\tA acurácia do Classificador GNB é: 74.24%\n",
      "\tA acurácia do Classificador MLP é: 73.66%\n",
      "\n",
      "Para o dataset social_network_ads:\n",
      "\tA acurácia do Classificador DTC é: 82.33%\n",
      "\tA acurácia do Classificador KNN é: 78.08%\n",
      "\tA acurácia do Classificador GNB é: 84.45%\n",
      "\tA acurácia do Classificador MLP é: 50.00%\n",
      "\n",
      "Para o dataset water_quality:\n",
      "\tA acurácia do Classificador DTC é: 78.43%\n",
      "\tA acurácia do Classificador KNN é: 57.12%\n",
      "\tA acurácia do Classificador GNB é: 69.98%\n",
      "\tA acurácia do Classificador MLP é: 76.46%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, dataset in enumerate(datasets_names):\n",
    "    print(f'Para o dataset {dataset}:')\n",
    "    print(f'\\tA acurácia do Classificador DTC é: {results_DTC[i][\"mean_test_score\"][0] :.2%}')\n",
    "    print(f'\\tA acurácia do Classificador KNN é: {results_KNN[i][\"mean_test_score\"][0] :.2%}')\n",
    "    print(f'\\tA acurácia do Classificador GNB é: {results_GNB[i][\"mean_test_score\"][0] :.2%}')\n",
    "    print(f'\\tA acurácia do Classificador MLP é: {results_MLP[i][\"mean_test_score\"][0] :.2%}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cs\n",
      "\tMLP, media: 0.7407156278081856, dp: 0.009854957169476897\n",
      "\tGNB, media: 0.7302671350379871, dp: 0.007144051038205445\n",
      "\tDTC, media: 0.6992892737521443, dp: 0.004474193623484673\n",
      "\tKNN, media: 0.6698880810391308, dp: 0.008363147416997365\n",
      "Dataset: breast_cancer\n",
      "\tGNB, media: 0.9265331890331889, dp: 0.03343992490690495\n",
      "\tDTC, media: 0.9253535353535354, dp: 0.03879138010935533\n",
      "\tMLP, media: 0.9198737373737375, dp: 0.02917625029840954\n",
      "\tKNN, media: 0.9041991341991343, dp: 0.029975390688040598\n",
      "Dataset: diabetes\n",
      "\tDTC, media: 0.9471741452991452, dp: 0.032332328890527\n",
      "\tMLP, media: 0.931090633903134, dp: 0.0382692812873986\n",
      "\tKNN, media: 0.9296594551282051, dp: 0.04477834365428389\n",
      "\tGNB, media: 0.5676923076923077, dp: 0.033517227849046684\n",
      "Dataset: driving_behavior\n",
      "\tMLP, media: 0.42015429775703755, dp: 0.029249537415903595\n",
      "\tGNB, media: 0.40120728586482013, dp: 0.046874711094433655\n",
      "\tDTC, media: 0.3674228511214813, dp: 0.03168339207227928\n",
      "\tKNN, media: 0.3542819509257865, dp: 0.01889796478090317\n",
      "Dataset: employee\n",
      "\tDTC, media: 0.7769499691953283, dp: 0.02424809134516806\n",
      "\tKNN, media: 0.7098446373084754, dp: 0.02901931371810383\n",
      "\tGNB, media: 0.6708712364727313, dp: 0.026647786650621334\n",
      "\tMLP, media: 0.6449869080145719, dp: 0.03896139659926067\n",
      "Dataset: go_to_college\n",
      "\tDTC, media: 0.8310000000000001, dp: 0.031448370387032756\n",
      "\tGNB, media: 0.724, dp: 0.03903844259188627\n",
      "\tKNN, media: 0.671, dp: 0.05838664230797999\n",
      "\tMLP, media: 0.5, dp: 0.0\n",
      "Dataset: phishing\n",
      "\tDTC, media: 0.9609371058763173, dp: 0.02007056255384461\n",
      "\tKNN, media: 0.9588900925339597, dp: 0.02311754156821395\n",
      "\tMLP, media: 0.9336383158339988, dp: 0.009958544492410161\n",
      "\tGNB, media: 0.6444087213599409, dp: 0.010951634908776433\n",
      "Dataset: smoking\n",
      "\tDTC, media: 0.7956665868596762, dp: 0.10221020423081259\n",
      "\tKNN, media: 0.7753974429186485, dp: 0.11237917107260173\n",
      "\tGNB, media: 0.7424087432689042, dp: 0.0034920443454949848\n",
      "\tMLP, media: 0.7366309098261118, dp: 0.013173753370281246\n",
      "Dataset: social_network_ads\n",
      "\tGNB, media: 0.8445384615384617, dp: 0.10319403940155542\n",
      "\tDTC, media: 0.8232783882783883, dp: 0.07175946134672376\n",
      "\tKNN, media: 0.7807875457875457, dp: 0.08332644861469017\n",
      "\tMLP, media: 0.5, dp: 0.0\n",
      "Dataset: water_quality\n",
      "\tDTC, media: 0.7843089942611777, dp: 0.13992236365517488\n",
      "\tMLP, media: 0.7646279119110273, dp: 0.16454433973912516\n",
      "\tGNB, media: 0.6997862500532015, dp: 0.14255836611335324\n",
      "\tKNN, media: 0.5712444007599436, dp: 0.10922072695501586\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datasets_algs = [[] for _ in range(len(datasets))]\n",
    "\n",
    "for i, algs in enumerate(datasets_algs):\n",
    "    algs.append({\"name\": \"DTC\", \"results\": results_DTC[i]})\n",
    "    algs.append({\"name\": \"KNN\", \"results\": results_KNN[i]})\n",
    "    algs.append({\"name\": \"GNB\", \"results\": results_GNB[i]})\n",
    "    algs.append({\"name\": \"MLP\", \"results\": results_MLP[i]})\n",
    "    algs.sort(key = lambda acc : acc[\"results\"][\"mean_test_score\"][0], reverse = True)\n",
    "\n",
    "    print(f'Dataset: {datasets_names[i]}')\n",
    "    for alg in algs:\n",
    "        print(f'\\t{alg[\"name\"]}, media: {alg[\"results\"][\"mean_test_score\"][0]}, dp: {alg[\"results\"][\"std_test_score\"][0]}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "diferenca_absoluta = [None] * 10\n",
    "\n",
    "for i, algs in enumerate(datasets_algs):\n",
    "    media_err_A0 = 1 - algs[0][\"results\"][\"mean_test_score\"][0]\n",
    "    dp_A0 = algs[0][\"results\"][\"std_test_score\"][0]\n",
    "\n",
    "    media_err_A1 = 1 - algs[1][\"results\"][\"mean_test_score\"][0]\n",
    "    dp_A1 = algs[1][\"results\"][\"std_test_score\"][0]\n",
    "\n",
    "    dif_media_err = media_err_A0 - media_err_A1\n",
    "    desvio_padrao = sqrt( (dp_A0**2 + dp_A1**2) / 2.0 )\n",
    "    diferenca_absoluta[i] = dif_media_err / desvio_padrao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cs, diferenca_absoluta: -1.2139662411911816\n",
      "MLP tem melhor performance que GNB\n",
      "\n",
      "Dataset: breast_cancer, diferenca_absoluta: -0.032573948099465254\n",
      "GNB tem melhor performance que DTC\n",
      "\n",
      "Dataset: diabetes, diferenca_absoluta: -0.45401077062389245\n",
      "DTC tem melhor performance que MLP\n",
      "\n",
      "Dataset: driving_behavior, diferenca_absoluta: -0.4849627703119523\n",
      "MLP tem melhor performance que GNB\n",
      "\n",
      "Dataset: employee, diferenca_absoluta: -2.5095177118972916\n",
      "DTC tem melhor performance que KNN com nível de confiança de 95%\n",
      "\n",
      "Dataset: go_to_college, diferenca_absoluta: -3.018578894707481\n",
      "DTC tem melhor performance que GNB com nível de confiança de 95%\n",
      "\n",
      "Dataset: phishing, diferenca_absoluta: -0.0945601955228326\n",
      "DTC tem melhor performance que KNN\n",
      "\n",
      "Dataset: smoking, diferenca_absoluta: -0.18869921889651706\n",
      "DTC tem melhor performance que KNN\n",
      "\n",
      "Dataset: social_network_ads, diferenca_absoluta: -0.23920639643380975\n",
      "GNB tem melhor performance que DTC\n",
      "\n",
      "Dataset: water_quality, diferenca_absoluta: -0.12886164988094084\n",
      "DTC tem melhor performance que MLP\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, algs in enumerate(datasets_algs):\n",
    "    print(f'Dataset: {datasets_names[i]}, diferenca_absoluta: {diferenca_absoluta[i]}')\n",
    "    if diferenca_absoluta[i] > 0:\n",
    "        if diferenca_absoluta[i] >= 2:\n",
    "            print(f'{algs[1][\"name\"]} tem melhor performance que {algs[0][\"name\"]} com nível de confiança de 95%')\n",
    "        else:\n",
    "            print(f'{algs[1][\"name\"]} tem melhor performance que {algs[0][\"name\"]}')\n",
    "    else:\n",
    "        if diferenca_absoluta[i] <= -2:\n",
    "            print(f'{algs[0][\"name\"]} tem melhor performance que {algs[1][\"name\"]} com nível de confiança de 95%')\n",
    "        else:\n",
    "            print(f'{algs[0][\"name\"]} tem melhor performance que {algs[1][\"name\"]}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "52cf93b3245c947d64d0217858e618f9641697b5c808500ce60698e2564fce2d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
